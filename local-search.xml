<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>PointNet++ 文献翻译阅读及拓展阅读</title>
    <link href="/2020/08/01/PointNet++%20%E6%96%87%E7%8C%AE%E7%BF%BB%E8%AF%91%E9%98%85%E8%AF%BB%E5%8F%8A%E6%8B%93%E5%B1%95%E9%98%85%E8%AF%BB/"/>
    <url>/2020/08/01/PointNet++%20%E6%96%87%E7%8C%AE%E7%BF%BB%E8%AF%91%E9%98%85%E8%AF%BB%E5%8F%8A%E6%8B%93%E5%B1%95%E9%98%85%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200330183554388.jpg?type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><h3 id="一、概览"><a href="#一、概览" class="headerlink" title="一、概览"></a>一、概览</h3><p><a href="https://arxiv.org/ftp/arxiv/papers/2003/2003.09644.pdf">论文地址：https://arxiv.org/ftp/arxiv/papers/2003/2003.09644.pdf</a><br><a href="https://github.com/charlesq34/pointnet2">代码下载：https://github.com/charlesq34/pointnet2</a><br><strong>论文框架：</strong><br><img src="https://img-blog.csdnimg.cn/20200330183722694.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><strong>研究目的：</strong> 增强 <a href="https://blog.csdn.net/maizousidemao/article/details/104855663">PointNet</a> 识别细粒度模式的能力和对复杂场景的泛化能力，使其能够能够高效、稳健地学习深层点集特征。</p><p><strong>解决方法：</strong> </p><ol><li>递归应用PointNet的分层神经网络来对输入点集进行嵌套划分。</li><li>在训练过程中借助随机输入丢失，学习对不同尺度上检测到的模式进行自适应加权，并根据输入数据对多尺度特征进行组合。</li></ol><p><strong>研究贡献：</strong> </p><ol><li>PointNet++在多个尺度上利用邻域来实现健壮性和细节捕捉，在学习关于距离度量的分层特征方面是有效的。</li><li>针对非均匀点采样问题，提出了两个新的集合抽象层，根据局部点密度智能聚合多尺度信息。</li></ol><p><strong>实验数据集：</strong> MNIST、ModelNet40、SHREC15、ScanNet</p><h3 id="二、相关工作"><a href="#二、相关工作" class="headerlink" title="二、相关工作"></a>二、相关工作</h3><p>分层特征学习的思想已经非常成功。在所有的学习模型中，卷积神经网络是最突出的模型之一。然而，卷积不适用于具有距离度量的无序点集，这是我们工作的重点。</p><p><a href="https://arxiv.org/abs/1612.00593">Pointnet</a> 和 <a href="https://arxiv.org/abs/1511.06391">Order matters</a> 研究了如何将深度学习应用于无序集合。但它们忽略了基础距离度量，即使只有一个点集。因此，它们无法捕获点的局部上下文，并且对全局集合转换和归一化敏感。在这项工作中，我们以从度量空间中采样的点为目标，并通过在设计中显式地考虑潜在的距离度量来解决这些问题。</p><p>从度量空间中采样的点通常带有噪声，并且采样密度不均匀。这影响了点特征的有效提取，给学习带来了困难。其中一个关键问题是为点特征设计选择合适的比例尺。以前，在几何处理领域或摄影测量和遥感领域，已经开发了几种方法来解决这一问题。与所有这些工作不同的是，我们的方法学会了以端到端的方式提取点特征和平衡多个特征尺度。</p><p>在3D度量空间中，除了点集，还有几种流行的深度学习表示法，包括体积网格和几何图。然而，在这些工作中，都没有明确地考虑到抽样密度不均匀的问题。</p><h3 id="三、本文方法"><a href="#三、本文方法" class="headerlink" title="三、本文方法"></a>三、本文方法</h3><h4 id="3-1-分层点集特征学习"><a href="#3-1-分层点集特征学习" class="headerlink" title="3.1 分层点集特征学习"></a>3.1 分层点集特征学习</h4><p>虽然PointNet使用单个最大合并操作来聚合整个点集，但我们的新体系结构建立了点的分层分组，并沿着层次逐步抽象越来越大的局部区域。<br><img src="https://img-blog.csdnimg.cn/20200330232039203.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>我们的层次结构由多个 set abstraction(这里不知道怎么翻译合适) 组成。在set abstraction，对一组点进行处理和抽象，以产生具有较少元素的新集合。set abstraction 由三个关键层组成：采样层、分组层和 PointNet 层。采样层从定义局部区域质心的输入点中选择一组点。然后，分组图层通过查找质心周围的“相邻”点来构建局部区域集。PointNet层使用迷你PointNet将局部区域模式编码为特征向量。<br>一个 set abstraction 以一个 $N×(d+C)$ 矩阵作为输入，该矩阵来自具有 $d$ 维坐标和 $C$ 维特征的 $N$ 个点。它输出一个$N^\prime×(d+C^\prime)$ 矩阵，这个矩阵具有 $N^\prime$ 个 $d$ 维坐标的二次采样点和总结局部上下文的新 $C^\prime$ 维的特征向量 。</p><p><strong>采样层</strong><br>给定输入点 ${x_1，x_2，…，x_n}$，我们使用迭代最远点采样(FPS)来选择点 ${x_{i1}，x_{i2}，…，x_{im}}$ 的子集，使得 $x_{ij}$ 是相对于其余点距离集合 ${x_{i1}，x_{i2}，…，x_{i_{j−1}}}$ 最远的点。与随机采样相比，在质心数目相同的情况下，该算法对整个点集的覆盖率更高。与扫描数据分布不可知的向量空间的CNN不同，我们的采样策略通过依赖于数据的方式生成 <a href="https://www.jianshu.com/p/2b968e7a1715">感受野(receptive fields)</a>。</p><p><strong>分组层</strong><br>该层的输入是大小为 $N×(d+C)$ 的点集和一组大小为 $N^\prime×d$ 的质心的坐标。输出是大小为 $N^\prime×K×(d+C)$ 的点集的组，其中每组对应于一个局部区域，$K$ 是质心点邻域中的点数。这里，$K$ 因组而异，但是随后的 PointNet 层能够将不同数量的点转换成固定长度的局部区域特征向量。<br>在卷积神经网络中，像素的局部区域由在特定曼哈顿距离内使用数组索引的像素 <a href="https://baike.baidu.com/item/%E6%9B%BC%E5%93%88%E9%A1%BF%E8%B7%9D%E7%A6%BB/743092?fr=aladdin">曼哈顿距离</a> 组成，这个特定的曼哈顿距离就是核大小。在从度量空间采样的点集中，点的邻域由度量距离来定义。</p><p><strong>PointNet 层</strong><br>在这一层中，输入的是数据大小为 $N^\prime×K×(d+C)$ 的点的 $N^\prime$ 个局部区域。输出中的每个局部区域从它的质心和编码质心邻域的局部特征中提取。输出数据大小为 $N^\prime×(d+C^\prime)$。<br>首先将局部区域中的点坐标转换成相对于质心点的局部框架：$x^{(j)}_i&#x3D;x^{(j)}_i−\hat x^{(j)}$，其中 $i&#x3D;1，2，…，K$，$j&#x3D;1，2，…，d$，其中 $\hat x$ 是质心的坐标。我们使用 PointNet 作为局部模式学习的基本构建模块，通过使用相对坐标和点特征，我们可以捕获局部区域内的点对点关系。</p><h4 id="3-2-非均匀采样密度下的鲁棒特征学习"><a href="#3-2-非均匀采样密度下的鲁棒特征学习" class="headerlink" title="3.2 非均匀采样密度下的鲁棒特征学习"></a>3.2 非均匀采样密度下的鲁棒特征学习</h4><p>如前所述，点集在不同区域的密度不均匀是很常见的。这种不均匀性给点集特征学习带来了巨大的挑战。在密集数据中学习的特征可能不会推广到稀疏采样区域。因此，为稀疏点云训练的模型可能无法识别细粒度的局部结构。<br>理想情况下，我们希望尽可能仔细地检查某个点集，以捕捉密集采样区域中的最精细细节。然而，这种近距离检查在低密度区域是被禁止的，因为局部特征可能会因采样不足而被破坏。在这种情况下，我们应该在更大的范围内寻找更大规模的特征。为了实现这一目标，我们提出了密度自适应PointNet层(如下图)，当输入采样密度改变时，该层学习合并来自不同尺度区域的特征。我们称我们的具有密度自适应 PointNet 层的分层网络为PointNet++。<br><img src="https://img-blog.csdnimg.cn/20200331213508767.jpg?type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>在PointNet++中，每个 set abstraction 提取多个尺度的局部模式，并根据局部点密度进行智能组合。通过对局部区域进行分组，结合不同尺度的特征，我们提出了两种密度自适应层，如下所示。</p><h5 id="3-2-1-多尺度分组-MSG"><a href="#3-2-1-多尺度分组-MSG" class="headerlink" title="3.2.1 多尺度分组(MSG)"></a>3.2.1 多尺度分组(MSG)</h5><p>如上图(a)所示，捕捉多尺度模式的一个简单而有效的方法是应用不同尺度的分组图层，然后根据相应的 PointNet 来提取每个尺度的特征。连接不同尺度的特征以形成多多尺度特征。<br>我们对网络进行训练，学习一种优化策略，将多尺度特征结合起来。这是通过为每个实例分配的随机概率随机丢弃输入点来实现的，我们称之为随机输入丢弃（random input dropout）。具体地说，对于每个训练点集合，我们从 $[0，p]$ 中选择一个均匀抽样的丢弃率 $θ$，其中 $p≤1$。对于每个点，我们以概率 $θ$ 随机丢弃。在实践中，我们设置 $p&#x3D;0.95$ 以避免生成空点集。在这样的过程中，我们给网络提供了各种稀疏性(由 $θ$ 引起)和不同均匀性(由丢弃的随机性引起)的训练集。测试期间，我们保留所有可用的分数。</p><h5 id="3-2-2-多分辨率分组-MRG"><a href="#3-2-2-多分辨率分组-MRG" class="headerlink" title="3.2.2 多分辨率分组(MRG)"></a>3.2.2 多分辨率分组(MRG)</h5><p>上面的MSG方法非常耗费计算资源，因为它为每个质心点在大规模的邻域中运行局部PointNet。具体地说，由于质心点的数量通常相当大，因此时间成本很大。在这里，我们提出了另一种方法，它避免了这种昂贵的计算，但仍然保留了根据点的分布属性自适应聚合信息的能力。在上图(b)中，某一级别的区域 $L_i$ 的特征是两个矢量的串联。一个矢量(图中左侧)是通过使用 set abstraction 从较低级别 $L_{i−1}$ 汇总每个子区域的特征来获得的。另一个矢量(右)是通过使用单个 PointNet 直接处理局部区域中的所有原始点而获得的特征。<br>当局部区域的密度较低时，第一向量可能比第二向量更不可靠，因为在计算第一向量时的子区域包含更稀疏的点，并且出现更多的采样不足。在这种情况下，第二个向量的权重应该更高。另一方面，当局部区域的密度较高时，由于第一向量具有在较低级别递归地以较高分辨率进行检查的能力，因此第一向量有更精细细节的信息。<br>与MSG方法相比，该方法避免了在最低层进行大规模邻域特征提取，计算效率更高。</p><h4 id="3-3-用于集合分割的点特征传播算法"><a href="#3-3-用于集合分割的点特征传播算法" class="headerlink" title="3.3 用于集合分割的点特征传播算法"></a>3.3 用于集合分割的点特征传播算法</h4><p>在集合抽象层中，对原始点集进行二次采样。然而，在集合分割任务中，如语义点标注，我们希望获得所有原始点的点特征。一种解决方案是始终将所有点采样为所有设置的抽象级别中的质心，但这会导致较高的计算成本。另一种方法是将特征从次采样点传播到原始点。<br>我们采用基于距离的插值和跨级跳过链接的分层传播策略。在特征传播层中，我们将点特征从 $N_l×(d+C)$ 点传播到 $N_{l−1}$ 点，其中 $N_{l−1}$ 和 $N_{l}(N_{l}≤N_{l−1})$ 是 set abstraction level $l$ 输入和输出的点集大小。我们通过在 $N_{l−1}$ 点的坐标上插值$N_{l}$ 点的特征值 $f$ 来实现特征传递。在众多插值选择中，我们使用基于 $k$ 近邻的反距离加权平均（下面公式中默认 $p &#x3D; 2, k &#x3D; 3$）。然后，将 $N_{l−1}$ 点上的插值特征与 set abstraction 中的跳过链接点特征连接起来。再将拼接的特征通过一个“单元 PointNet”，这类似于 CNNs 中的逐个卷积。应用几个共享全链接和 ReLU 层来更新每个点的特征向量。重复该过程，直到我们将特征传递到原始点集。</p><p>$$<br>f^{(j)}(x)&#x3D;\frac{\sum^k_{i&#x3D;1}w_i(x)f^{(j)}<em>i}{\sum^k</em>{i&#x3D;1}w_i(x)} ,其中，w_i(x)&#x3D;\frac{1}{d(x,x_i)^p},j&#x3D;1,…,C<br>$$</p><h3 id="四、实验"><a href="#四、实验" class="headerlink" title="四、实验"></a>四、实验</h3><p><strong>数据集</strong>：MNIST、ModelNet40、SHREC15、ScanNet</p><h4 id="4-1-欧氏度量空间中的点集分类"><a href="#4-1-欧氏度量空间中的点集分类" class="headerlink" title="4.1 欧氏度量空间中的点集分类"></a>4.1 欧氏度量空间中的点集分类</h4><p>我们对从 2D(MNIST) 和 3D(ModleNet40) 欧几里德空间采样的点云进行了分类，并对我们的网络进行了评估。<br>把 MNIST 图像转换为具有数字像素位置的二维点云，从 ModelNet40 形状的网格曲面采样三维点云。默认情况下，我们对 MNIST 使用 512 点，对 ModelNet40 使用 1024 点。在下图表2的最后一行(我们的 baseline )中，我们使用面法线作为附加点特性，其中我们还使用更多的点(N&#x3D;5000)来进一步提高性能。所有点集都归一化为零平均值，并且在一个单位球内。我们使用具有三个全连接层的三级分层网络。<br>对于MNIST图像，我们首先将所有像素的亮度归一化到 $[0，1]$ 范围内，然后选择所有强度大于 $0.5$ 的像素作为有效的数字像素。然后，我们将图像中的数字像素转换为坐标在 $[−1，1]$ 内的二维点云，其中图像中心是原点。创建扩充点是为了将设置为固定基数的点添加到固定基数(在我们的示例中为512)。我们抖动初始点云(随机平移高斯分布 $N(0，0.01)$ 并修剪到 $0.03$ )以生成增强点。对于ModelNet40，我们基于面面积从CAD模型曲面中均匀采样 $N$ 个点。<br>对于所有实验，我们使用学习率为 $0.001$ 的 <a href="https://arxiv.org/abs/1412.6980">ADAM</a> 优化器进行训练。对于数据增强，我们使用随机缩放对象、扰动对象位置和点样本位置的方法。我们还遵循<a href="https://arxiv.org/abs/1604.03265">V olumetric and multi-view cnns for object<br>classification on 3d data</a>随机旋转对象的方法以进行ModelNet40数据增强。我们使用 TensorFlow 和 GTX 1080、Titan X 进行训练，所有层都在 CUDA 中实现，以运行 GPU。将我们的模型训练到收敛大约需要20个小时。</p><p><strong>实验结果</strong><br><img src="https://img-blog.csdnimg.cn/20200331223032373.jpg?type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>在表1和表2中，我们将我们的方法与以前技术水平的代表性集合进行了比较。请注意，表2中的 PointNet(Vanilla) 是 <a href="https://blog.csdn.net/maizousidemao/article/details/104855663">PointNet</a> 中不使用转换网络的版本，这相当于我们的分层网络只有一个级别。<br>在MNIST中，我们看到 PointNet(Vanilla) 和 PointNet 与我们的方法相比错误率分别降低了 $60.8%$ 和 $34.6%$。在 ModelNet40 分类中，我们还看到，使用相同的输入数据大小(1024个点)和特征(仅坐标)，我们的分类比 PointNet 强得多。其次，我们观察到基于点集的方法甚至可以获得比成熟的图像CNN更好或相近的性能。在 MNIST 中，我们的方法(基于二维点集)在网络CNN中达到了接近网络的精度。在 ModelNet40 中，我们使用普通信息的方法明显优于以前的最先进的方法 MVCNN。</p><p><strong>对采样密度变化的鲁棒性分析</strong><br>直接从真实世界获取的传感器数据通常存在严重的不规则采样问题，如下图。我们的方法选择多个尺度的点邻域，并通过对它们进行适当的加权来学习平衡描述性和鲁棒性。<br><img src="https://img-blog.csdnimg.cn/20200331225651586.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>我们在测试期间随机落点(见下图左侧)，以验证我们的网络对非均匀和稀疏数据的鲁棒性。在下图右侧，我们看到 MSG+DP (在训练期间具有随机输入丢弃的多尺度分组)和 MRG+DP 对采样密度变化非常稳健。从1024个测试点到256个测试点，MSG+DP性能下降不到 $1%$ 。此外，与其他方法相比，它在几乎所有的采样密度上都取得了最好的性能。PointNet vanilla 在密度变化下相当健壮，这是因为它关注全局抽象而不是精细细节。然而，与我们的方法相比，丢失细节也会使其功能较弱。SSG(Ablated PointNet++，每级单尺度分组)不能推广到稀疏采样密度，而 SSG+DP 通过在训练时间内随机丢弃点来弥补这一问题。<br><img src="https://img-blog.csdnimg.cn/20200331225805558.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><h4 id="4-2-面向语义场景标注的点集分割"><a href="#4-2-面向语义场景标注的点集分割" class="headerlink" title="4.2 面向语义场景标注的点集分割"></a>4.2 面向语义场景标注的点集分割</h4><p>为了验证我们的方法适用于大规模的点云分析，我们还对语义场景标注任务进行了评估。</p><p>目标是预测室内扫描中点的语义对象标签。<a href="https://arxiv.org/abs/1702.04405">ScanNet</a> 在体素化扫描上使用完全卷积神经网络作为我们的 baseline。它们纯粹依赖于扫描几何体而不是RGB信息，并以每个体素为基础报告精确度。为了进行公平的比较，我们在所有的实验中都去掉了RGB信息，并按照 ScanNet 将点云标签预测转换为体素标签。我们还与 PointNet 进行了比较。<br>我们的方法在很大程度上超过了所有的 baseline 方法。与在体素化扫描上学习的 ScanNet 相比，我们直接在点云上学习，避免了额外的量化误差，并进行数据相关采样，以实现更有效的学习。与文献 PointNet 相比，该方法引入了分层特征学习，捕获了不同尺度的几何特征。这对于了解多个级别的场景和标记各种大小的对象非常重要。</p><p><strong>实验结果</strong><br>下图蓝色条代表基于每个体素的精度。<br><img src="https://img-blog.csdnimg.cn/20200331231406985.jpg?type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>下图可见，PointNet 正确捕捉房间的总体布局，但找不到家具。相比之下，除了房间布局之外，我们的方法在分割对象方面要好得多。<br><img src="https://img-blog.csdnimg.cn/20200331231349979.jpg?type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><strong>对采样密度变化的鲁棒性分析</strong><br>为了测试我们的训练模型在非均匀采样密度的扫描上的性能，我们合成了 Scannet 场景的虚拟扫描，并在此数据上评估了我们的网络。我们在三种设置(SSG、MSG+DP、MRG+DP)中评估我们的框架，并与基线方法 PointNet 进行比较。<br>为了从 ScanNet 场景生成训练数据，我们从初始场景采样 $1.5m×1.5m×3m$ 的立方体，然后将立方体保留在 $≥2%$ 的体素被占用并且 $≥70%$ 的表面体素具有有效注释的位置。我们在运行中对这样的训练立方体进行采样，并沿着右上轴随机旋转它。将增强点添加到点集，以形成固定基数(在我们的示例中为8192)。在测试期间，我们类似地将测试场景分割成更小的立方体，首先获得立方体中每个点的标签预测，然后合并同一场景中所有立方体中的标签预测。如果一个点从不同的立方体获得不同的标签，我们只需进行多数投票就可以得到最终的点标签预测。<br>性能比较如<strong>实验结果</strong>中黄条所示。我们看到，由于采样密度从均匀的点云转移到虚拟扫描的场景，SSG的性能大大降低。另一方面，MRG网络对采样密度漂移的鲁棒性更强，因为它能够在采样稀疏时自动切换到描述较粗粒度的特征。即使训练数据(均匀的点随机丢失)和密度不均匀的扫描数据之间存在领域差距，但我们的MSG网络受到的影响很小，在各种方法中达到了最好的准确率。这些都证明了我们的密度自适应层设计的有效性。</p><h4 id="4-3-非欧氏度量空间中的点集分类"><a href="#4-3-非欧氏度量空间中的点集分类" class="headerlink" title="4.3 非欧氏度量空间中的点集分类"></a>4.3 非欧氏度量空间中的点集分类</h4><p>在这一实验中，我们展示了我们的方法在非欧几里德空间上的推广。解决同一个物体不同姿态的识别问题。</p><p><img src="https://img-blog.csdnimg.cn/20200401121257288.jpg?type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>在非刚性形状分类中，一个好的分类器应该能够将图中的 (a) 和 (c) 正确地分类为相同的类别，即使它们的姿势不同，这需要内在结构的信息。SHREC15 中的形状是嵌入在三维空间中的二维曲面。沿曲面的测地线距离自然会产生度量空间。（Geodesic distances along the surfaces<br>naturally induce a metric space. ）实验表明，在该度量空间中采用 PointNet++ 是捕捉底层点集内在结构的有效途径。</p><p>对于文 <a href="https://www.cs.cf.ac.uk/shaperetrieval/files/Lian_3DOR_2015.pdf">SHREC15 Track</a> 中的每种形状，我们首先构造了由成对测地距离诱导的度量空间。（we firstly construct the metric space in-<br>duced by pairwise geodesic distances.）使用 <a href="https://gfx.cs.princeton.edu/pubs/Rustamov_2009_IDU/paper.pdf">Interior distance using barycentric coordinates</a> 的方法来获得模拟测地距离的嵌入度量。接下来，我们提取该度量空间中的本征点特征，包括 <a href="http://imagine.enpc.fr/~aubrym/projects/wks/texts/2011-wave-kernel-signature.pdf">WKS</a>、<a href="http://www.lix.polytechnique.fr/~maks/papers/hks.pdf">HKS</a> 和 <a href="http://www.geometry.caltech.edu/pubs/DMSB_III.pdf">多尺度高斯曲率</a>。我们使用这些特征作为输入，然后根据底层度量空间对点进行采样和分组。通过这种方式，我们的网络学会了捕捉不受形状特定姿态影响的多尺度内在结构。另一种设计选择包括使用 $XYZ$ 坐标作为点要素或使用欧几里得空间 $\Bbb R^3$ 作为底层度量空间。实验结果显示，这些都不是最佳选择。</p><p>实验细节：<br>我们在每个形状上随机抽样 1024 个点进行训练和测试。为了生成输入的固有特征，我们分别提取100维的 WKS、HKS 和多尺度高斯曲率，得到每个点的 300 维特征向量。然后进行主成分分析，将特征维数降至 64。我们在  <a href="https://gfx.cs.princeton.edu/pubs/Rustamov_2009_IDU/paper.pdf">Interior distance using barycentric coordinates</a>  后面用一个 8 维的嵌入来模拟测地线距离，它被用来描述我们的非欧几里德度量空间，同时选择点的邻域。</p><p><strong>实验结果：</strong><br><img src="https://img-blog.csdnimg.cn/20200401183458986.jpg#pic_center" alt="在这里插入图片描述"><br><a href="https://www.researchgate.net/publication/316912821_Deep_Learning_with_Geodesic_Moments_for_3D_Shape_Classification">DeepGM</a> 提取测地线矩作为形状特征，并使用堆叠式稀疏自动编码器来处理这些特征并预测形状类别。我们的方法使用了非欧几里德度量空间和固有特征，在所有设置下都取得了最好的性能，并且大大超过了 DeepGM。</p><h4 id="4-4-特征可视化"><a href="#4-4-特征可视化" class="headerlink" title="4.4 特征可视化"></a>4.4 特征可视化</h4><p><img src="https://img-blog.csdnimg.cn/20200401185519380.jpg?type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>我们将通过分层网络的第一层核学习到的内容可视化。在空间中创建了一个体素网格，并聚合了在网格单元中激活神经元最多的局部点集(使用了最高100个示例)。高投票率的网格单元被保留下来，并转换回三维点云，这代表了神经元识别的模式。由于模型是在主要由家具组成的 ModelNet40 上训练的，所以在可视化中我们可以看到平面、双平面、线、角等结构。</p><h3 id="五、结论"><a href="#五、结论" class="headerlink" title="五、结论"></a>五、结论</h3><p>在这项工作中，我们提出了 PointNet++，这是一个强大的神经网络体系结构，用于处理度量空间中采样的点集。PointNet++ 递归地作用于输入点集的嵌套划分，并且在学习关于距离度量的分层特征方面是有效的。针对非均匀点采样问题，我们提出了两个新的集合抽象层，根据局部点密度智能聚合多尺度信息。这些贡献使我们能够在具有挑战性的三维点云基准上获得最先进的性能。<br>如何通过在每个局部区域共享更多的计算来提高网络的推理速度，特别是MSG层和MRG层的推理速度，是今后值得思考的问题。同样有趣的是，在高维度量空间中，基于CNN的方法在计算上是不可行的，而我们的方法可以很好地扩展。</p>]]></content>
    
    
    <categories>
      
      <category>PointNet++</category>
      
    </categories>
    
    
    <tags>
      
      <tag>点云</tag>
      
      <tag>文献</tag>
      
      <tag>深度学习</tag>
      
      <tag>计算机视觉</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PointNet 文献翻译阅读及拓展阅读</title>
    <link href="/2020/07/26/PointNet%20%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%8F%8A%E6%8B%93%E5%B1%95%E9%98%85%E8%AF%BB/"/>
    <url>/2020/07/26/PointNet%20%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%8F%8A%E6%8B%93%E5%B1%95%E9%98%85%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200314101022955.jpg" alt="在这里插入图片描述"></p><h3 id="一、概览"><a href="#一、概览" class="headerlink" title="一、概览"></a>一、概览</h3><p><a href="https://arxiv.org/pdf/1612.00593.pdf">论文地址：https://arxiv.org/pdf/1612.00593.pdf</a><br><a href="https://github.com/charlesq34/pointnet">代码下载：https://github.com/charlesq34/pointnet</a><br><strong>论文框架：</strong><br><img src="https://img-blog.csdnimg.cn/20200314101754204.png#pic_center" alt="在这里插入图片描述"><br><strong>研究目的：</strong> 利用深度学习网络处理三维点云数据。</p><p><strong>研究思路：</strong> 首先通过对齐网络保证点云对特定空间转换的不变性，然后将全局特征和局部特征进行串联，综合利用特征。</p><p><strong>解决方法：</strong> 提出PointNet —— 一种直接对三维几何数据(如点云或网格)进行处理的深度学习模型。</p><p><strong>研究贡献：</strong> </p><ol><li>设计了一种直接输入三维无序点集的新型深度网络体系结构。</li><li>解决点云对特定空间转换的不变性。</li><li>展示了如何训练这样的网络来执行3D形状分类、形状部分分割和场景语义分析任务。</li></ol><p><strong>实验数据集：</strong> ModelNet40、ShapeNet、Stanford 3D semantic parsing data set </p><h3 id="二、关于点云"><a href="#二、关于点云" class="headerlink" title="二、关于点云"></a>二、关于点云</h3><p><strong>点云的概念：</strong> 点云是在同一空间参考系下表达目标空间分布和目标表面特性的海量点集合，包含了丰富的信息，可以是三维坐标X，Y，Z、颜色、强度值、时间等等。点云本质上是一长串点（Nx3矩阵，其中n是点数）。</p><p><strong>点云包含的信息：</strong> </p><ol><li><strong>根据激光测量原理得到的点云，包括三维坐标（XYZ）和激光反射强度（Intensity）</strong>，强度信息与目标的表面材质、粗糙度、入射角方向，以及仪器的发射能量，激光波长有关。</li><li><strong>根据摄影测量原理得到的点云，包括三维坐标（XYZ）和颜色信息（RGB）。</strong></li><li><strong>结合激光测量和摄影测量原理得到点云，包括三维坐标（XYZ）、激光反射强度（Intensity）和颜色信息（RGB）。</strong></li></ol><p><strong>点云处理方法：</strong><br><img src="https://img-blog.csdnimg.cn/20200317202343344.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>点云数据是在欧式空间下的点的一个子集，它具有以下三个特征：</p><h4 id="2-1-无序性"><a href="#2-1-无序性" class="headerlink" title="2.1. 无序性"></a>2.1. 无序性</h4><p>与图像中的像素阵列或体积网格中的体素阵列不同，点云是一组没有特定顺序的点。<br>点云数据是一个集合，对数据的顺序是不敏感的。这就意味着处理点云数据的模型需要对数据的不同排列保持不变性。<br>目前文献中使用的方法包括：</p><ol><li>将无序的数据重排序。</li><li>用数据的所有排列进行数据增强然后使用RNN模型。</li><li>用对称函数来保证排列不变性。</li></ol><p>由于第三种方式的简洁性且容易在模型中实现，论文作者选择使用第三种方式，既使用maxpooling 这个对称函数来提取点云数据的特征。</p><h5 id="2-2-点与点之间的空间关系"><a href="#2-2-点与点之间的空间关系" class="headerlink" title="2.2. 点与点之间的空间关系"></a>2.2. 点与点之间的空间关系</h5><p>一个物体通常由特定空间内一定数量的点云构成，也就是说这些点云之间存在着空间关系。因此，模型需要能够捕捉附近点的局部结构，以及局部结构之间的组合相互作用。为了能有效利用这种空间关系，论文作者提出了将局部特征和全局特征进行串联的方式来聚合信息。</p><h5 id="2-3-刚性变换不变性"><a href="#2-3-刚性变换不变性" class="headerlink" title="2.3. 刚性变换不变性"></a>2.3. 刚性变换不变性</h5><p>点云数据所代表的目标对某些空间变换应该具有不变性，如旋转和平移等刚性变换。论文作者提出了在进行特征提取之前，先对点云数据进行对齐的方式来保证不变性。对齐操作是通过训练一个小型的网络来得到变换矩阵，并将之和输入点云数据相乘来实现。</p><h3 id="三、现阶段研究"><a href="#三、现阶段研究" class="headerlink" title="三、现阶段研究"></a>三、现阶段研究</h3><p><strong>3.1. Point Cloud Features</strong><br>大多数现有的点云功能都是针对特定任务手工创建的。点特征通常编码某些点的统计属性，并且被设计成对某些变换是不变的，这些变换通常被分类为内部的或外部的。它们还可以分为局部特征和全局特征。对于特定的任务，要找到最优的特征组合并不是一件容易的事。</p><p><strong>3.2. Deep Learning on 3D Data</strong><br>根据3D数据的表示不同有多种深度学习的方法<br><strong>Volumetric CNNs：</strong> 通过将物体表现为空间中的体素进行类似于二维的三维卷积。然而，由于三维卷积的数据稀疏性和计算开销，体素表示受到其时间和空间复杂度的限制，对于处理非常大的点云具有挑战性，目前已经不是主流的方法了。</p><p><strong>Multiview CNNs：</strong> 通过多视角二维图片组合为三维物体，此方法将传统CNN应用于多张二维视角的图片，特征被view pooling procedure聚合起来形成三维物体。</p><p><strong>Spectral CNNs：</strong> 在网格上使用谱CNNs。然而，这些方法目前仅限于有机对象等多种网格上，如何将其扩展到非等轴测形状(如家具)上并不明显。</p><p><strong>Feature-based DNNs：</strong> 首先通过提取传统的形状特征将三维数据转化为向量，然后使用全连通网络对形状进行分类。我们认为它们受到所提取特征的表征能力的限制。</p><p><strong>3.3. Deep Learning on Unordered Sets</strong><br>从数据结构的角度来看，点云是一组无序的矢量。虽然大多数深度学习的研究都集中在规则的输入上，如序列(语音和语言处理)、图像和体积(视频或3D数据)，但在点集的深度学习方面却没有做太多的工作。<br><a href="https://arxiv.org/pdf/1511.06391.pdf">Oriol Vinyals</a>等人最近的一项研究探讨了这个问题。他们使用一个带有注意力机制的 read-process-write 网络来消费无序的输入集，并表明他们的网络具有对数字进行排序的能力。然而，由于他们的工作集中在一般集合和NLP应用上，在集合中缺少几何学的作用。</p><h3 id="四、本文方法"><a href="#四、本文方法" class="headerlink" title="四、本文方法"></a>四、本文方法</h3><p>点云表示为一组三维点 ${P_i | i&#x3D;1,…,n}$，其中每个点 $P_i$ 都是 $(x，y，z)$ 坐标的向量加上额外的功能通道（如颜色、法线等）。为简单和清晰起见，除非另有说明，否则我们仅使用 $(x，y，z)$ 坐标作为点的表示。</p><p>我们网络架构的灵感来自于 $\Bbb R^n$ 中的点集属性。</p><h4 id="4-1-Bbb-R-n-中点集的属性-Properties-of-Point-Sets-in-Bbb-R-n"><a href="#4-1-Bbb-R-n-中点集的属性-Properties-of-Point-Sets-in-Bbb-R-n" class="headerlink" title="4.1. $\Bbb R^n$ 中点集的属性 (Properties of Point Sets in $\Bbb R^n$)"></a>4.1. $\Bbb R^n$ 中点集的属性 (Properties of Point Sets in $\Bbb R^n$)</h4><p>我们的输入是来自欧几里得空间的点的子集。它有三个主要属性：</p><ol><li>无序性</li><li>点之间的空间关系</li><li>刚性变换不变性<br><strong>（此部分已在 “二、关于点云” 中详细说明）</strong></li></ol><h4 id="4-2-PointNet-架构-PointNet-Architecture"><a href="#4-2-PointNet-架构-PointNet-Architecture" class="headerlink" title="4.2. PointNet 架构 (PointNet Architecture)"></a>4.2. PointNet 架构 (PointNet Architecture)</h4><p><img src="https://img-blog.csdnimg.cn/20200318102313146.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>原文说明：<br>该分类网络（Classification Network，图中蓝色部分）以 $n$ 个点为输入，应用输入和特征变换，然后通过最大池化（max pool）的方法聚合点特征。输出是 $k$ 个类的分类分数。分段网络（Segmentation Network，图中浅黄色部分）是分类网络的扩展。它将全局和局部特征以及每类分数的输出连接在一起。“MLP”代表多层感知机，括号中的数字为层大小。Batchnorm用于具有RELU的所有层。丢弃层用于分类网络中的最后一个MLP。</p><p><strong>网络主要流程为：</strong></p><ol><li>输入为一帧的全部点云数据的集合，表示为一个nx3的2d tensor，其中n代表点云数量，3对应xyz坐标。</li><li>输入数据先通过和一个T-Net学习到的转换矩阵相乘来对齐（input transform），保证了模型对特定空间转换的不变性。</li><li>通过多次mlp对各点云数据进行特征提取后，再用一个T-Net对特征进行对齐（feature transform）。<br>在特征的各个维度上执行最大池化（max pool）操作来得到最终的全局特征。</li><li>对分类任务，将全局特征通过mlp来预测最后的分类分数；</li><li>对分割任务，将全局特征和之前学习到的各点云的局部特征进行串联，再通过mlp得到每个数据点的分类结果。</li></ol><p>我们的网络有三个关键模块：</p><ul><li>作为从所有点聚合信息的对称函数的最大池化层</li><li>局部和全局信息组合结构</li><li>两个同时对齐输入点和点要素的联合对齐网络</li></ul><p>我们将在下面的单独段落中讨论这些设计选择背后的原因：</p><h5 id="4-2-1-无序输入的对称函数（Symmetry-Function-for-Unordered-Input）"><a href="#4-2-1-无序输入的对称函数（Symmetry-Function-for-Unordered-Input）" class="headerlink" title="4.2.1 无序输入的对称函数（Symmetry Function for Unordered Input）"></a>4.2.1 无序输入的对称函数（Symmetry Function for Unordered Input）</h5><p>该部分位于分类网络中（图中蓝色部分），构建分类网络主体。（个人理解）<br>前面已经说过，对于无序输入，目前文献中使用的方法包括：</p><ol><li>将无序的数据重排序。</li><li>用数据的所有排列进行数据增强然后使用RNN模型。</li><li>用对称函数来保证排列不变性。</li></ol><p>文章指出，重新排序的方法，在高维空间中对于点扰动并不稳定。而使用RNN的想法将点集视为顺序信号，并希望通过用随机排列的序列训练RNN，数据的顺序将按照输入顺序固定不变，<a href="https://arxiv.org/pdf/1511.06391.pdf">OrderMatters</a> 已经证明了顺序确实很重要，不能完全省略。虽然RNN对于长度较小(几十个)的序列的输入排序具有相对较好的鲁棒性，但很难扩展到数千个输入元素，而这是点集的常见大小。</p><p>为了使结果不受输入排列顺序的影响，本文作者提出通过对集合中的元素应用对称函数来近似定义在点集上的一般函数：<br>$$<br>f({x_1,…,x_n})&#x3D;g(h(x_1),…,h(x_n))<br>$$<br>其中<br>$$<br>f:2^{\Bbb R^N}\to\Bbb R,<br>h:\Bbb R^N\to\Bbb R^K,<br>g:\underbrace{\Bbb R^K\times···\times\Bbb R^K}_{n}\to\Bbb R<br>$$<br>$g$ 是一个对称函数，用单变量函数和最大池化函数的组合来拟合。$h$ 用多层感知机网络（mlp）拟合，用于将点云数据映射到高维。</p><h5 id="4-2-2-整合局部信息和全局信息（Local-and-Global-Information-Aggregation）"><a href="#4-2-2-整合局部信息和全局信息（Local-and-Global-Information-Aggregation）" class="headerlink" title="4.2.2 整合局部信息和全局信息（Local and Global Information Aggregation）"></a>4.2.2 整合局部信息和全局信息（Local and Global Information Aggregation）</h5><p>该部分是分段网络（图中浅红色部分）。<br>上一步（分类网络）输出一个向量 $[f_1,…,f_K]$，是输入的点云数据的全局特征信息，在计算出全局点云特征向量后，通过将全局特征与每个点特征连接起来，再将其反馈给每个点特征。然后，基于组合点提取新的逐点特征，这样新的逐点特征同时知道局部和全局信息。<br>我们的网络能够预测依赖于局部几何和全局语义的每个点的数量。例如，我们可以准确地预测每个点的法线，验证网络能够汇总来自点的局部邻域信息。实验表明，该模型在形状分割和场景分割方面都达到了最好的效果。<br>PointNet 法线重建结果：<br><img src="https://img-blog.csdnimg.cn/2020032210163525.jpg#pic_center" alt="在这里插入图片描述"></p><h5 id="4-2-3-联合定位网络（Joint-Alignment-Network）"><a href="#4-2-3-联合定位网络（Joint-Alignment-Network）" class="headerlink" title="4.2.3 联合定位网络（Joint Alignment Network）"></a>4.2.3 联合定位网络（Joint Alignment Network）</h5><p>如果点云经过某些几何变换(如刚性变换)，则点云的语义标签必须是不变的。因此，我们期望通过我们的点集学习的表示对于这些变换是不变的。<br>自然的解决方案是在特征提取之前将所有输入集合与规范空间对齐。如 Max Jaderberg 等人的 <a href="https://arxiv.org/abs/1506.02025">Spatial Transformer Networks</a>，通过采样和插值来对齐2D图像，并在GPU上实现了一个专门定制的层。<br>我们通过一个微型网络（T-net）预测一个仿射变换矩阵，并将这个变换直接应用到输入点的坐标上。T-net 本身类似于大网络，由点无关特征提取、最大集合和全连通三个基本模块组成。第一个 T-net 以原始点云为输入，回归为 $3×3$ 矩阵的迷你点网(Mini-PointNet)。由每个点上的共享MLP(64，128，1024)网络(层输出大小为64，128，1024)、跨点的最大池和两个输出大小为512，256的完全连接层组成。输出矩阵被初始化为单位矩阵。除最后一层外，所有层都包含重新生成和批处理规格化。第二个 T-net 除了输出为64×64矩阵外，网络结构与第一个相同。</p><p>这一思想也可以进一步推广到特征空间的对齐问题。我们可以在点要素上插入另一个对齐网络，并预测一个特征转换矩阵来对齐来自不同输入点云的特征。然而，特征空间中的变换矩阵比空间变换矩阵的维数要高得多，极大地增加了优化的难度。因此，我们将正则化项添加到 Softmax 训练损失中。我们将特征变换矩阵约束为接近正交矩阵：</p><p>$$<br>L_{reg} &#x3D; ||I - AA^T||^2_F<br>$$</p><p>其中A是由 T-net 预测的特征对齐矩阵。我们发现，通过添加正则项，优化变得更加稳定，我们的模型取得了更好的性能。</p><h4 id="4-3-理论分析（Theoretical-Analysis）"><a href="#4-3-理论分析（Theoretical-Analysis）" class="headerlink" title="4.3. 理论分析（Theoretical Analysis）"></a>4.3. 理论分析（Theoretical Analysis）</h4><h5 id="4-3-1-网络对函数的拟合能力"><a href="#4-3-1-网络对函数的拟合能力" class="headerlink" title="4.3.1 网络对函数的拟合能力"></a>4.3.1 网络对函数的拟合能力</h5><p>对于一个处理点云的网络，通过集合函数的连续性，对输入点集合的微小扰动应该不会对函数值有很大的改变，例如分类或分割分数。<br>设 $\chi&#x3D;{S:S\subseteq[0,1]^m and |S|&#x3D;n}$，而 $f:\chi\to\Bbb R$ 是 $\chi$ 上关于<a href="https://blog.csdn.net/maizousidemao/article/details/105030333">Hausdorff 距离</a> $d_H(·,·)$ 的连续集函数。即在m维欧式空间中， $\forall\epsilon&gt;0,\exists\delta&gt;0$，对任意 $S,S^\prime \in \chi$，如果 $d_H(S,S^\prime)&lt;\delta$，则 $|f(S)-f(S^\prime)|&lt;\epsilon$。<strong>如果在最大池化层有足够多的神经元，即 $(2.1)$ 中公式的 $K$ 足够大，PointNet 可以拟合任意的函数。</strong></p><p>然后作者又给出两个定理：<br><strong>Theorem 1.</strong><br>设 $f:\chi\to\Bbb R$ 是 $\chi$ 是关于<a href="https://blog.csdn.net/maizousidemao/article/details/105030333">Hausdorff 距离</a> $d_H(·,·)$ 的连续集函数，$\forall\epsilon&gt;0$，存在连续函数 $h$ 和对称函数 $g(x_1,…,x_n)&#x3D;\gamma \circ MAX$，使得对任意 $S \in \chi$ ，有：<br>( 注：$f \circ g&#x3D;f(g)$ )</p><p>$$<br>\begin{vmatrix}<br>f(S)-\gamma \left(\underset{i&#x3D;1,…,n}{MAX}{h(x_i)}\right)<br>\end{vmatrix}<br>&lt; \epsilon<br>$$</p><p>其中，$x_1,…,x_n$ 是 $S$ 中任意排序元素的完整列表，$\gamma$ 是一个连续函数，$MAX$ 是向量最大运算符，它接受 $n$ 个向量作为输入，并返回一个包含各向量元素最大值的新向量。<br>这一定理主要是为了说明，PointNet 网络的表达能力受到最大池化层的维数的影响，即 $(2.1)$ 中的 $K$，$K$ 越大网络表达能力越强。</p><h5 id="4-3-2-网络的稳定性"><a href="#4-3-2-网络的稳定性" class="headerlink" title="4.3.2 网络的稳定性"></a>4.3.2 网络的稳定性</h5><p>下面的定理告诉我们，输入集中的小数据损坏或额外噪声点不太可能改变我们网络的输出：<br><strong>Theorem 2.</strong><br>假设 $u:\chi \to \Bbb R^K$ 使得 $u&#x3D;\underset{i&#x3D;1,…,n}{MAX}{h(x_i)}$，并且 $f&#x3D;\gamma\circ u$ ，那么，<br>$（a）若 C_S \subseteq T \subseteq N_S,则 \forall S,\exist C_S,N_S \subseteq \chi,f(T)&#x3D;f(S)$<br>$（b）|C_S|\leq K$</p><p>（a）这一定理表明，对于任何输入数据集 $S$，都存在一个最小集 $C_S$ 和一个最大集 $N_S$，使得对 $C_S$ 和 $N_S$ 之间的任何集合 $T$，其网络输出都和 $S$ 一样。<br>（b）说明了最小集 $C_S$ 的数据多少由最大池化操作输出数据的维度 $K$ 给出上界。换个角度来讲，PointNet 能够总结出表示某类物体形状的关键点，基于这些关键点 PointNet 能够判别物体的类别。这样的能力决定了 PointNet 对噪声和数据缺失的鲁棒性。</p><h3 id="五、实验"><a href="#五、实验" class="headerlink" title="五、实验"></a>五、实验</h3><p>实验分为四个部分。</p><ol><li>展示了 PointNets 可以应用于多个3D识别任务。</li><li>提供了详细的实验来验证我们的网络设计。</li><li>将网络学习的内容可视化。</li><li>分析时间和空间复杂度。</li></ol><h4 id="5-1-应用"><a href="#5-1-应用" class="headerlink" title="5.1. 应用"></a>5.1. 应用</h4><p><strong>5.1.1 三维对象分类</strong><br><strong>实验设计：</strong><br>使用 ModelNet40 形状分类基准（数据集），包括来自40个人造物体类别的 12311 个CAD模型，分为 9843 个用于训练和 2468 个用于测试。<br>按照面面积对网格面上的1024个点进行均匀采样，并将其归一化为一个单位球面。在训练过程中，通过沿上轴（指向上方的坐标轴）随机旋转对象来动态增强点云，并用均值为0，标准差为0.02的高斯噪声抖动每个点的位置。</p><p><strong>实验结果：</strong><br><img src="https://img-blog.csdnimg.cn/20200325140545167.jpg#pic_center" alt="在这里插入图片描述"><br>虽然比大多数网络先进，但和基于多视图的方法(<a href="https://arxiv.org/abs/1505.00880">MVCNN</a>)还有差距，作者认为这是由于丢失了渲染图像可以捕捉到的精细几何细节导致的。</p><p><strong>5.1.2 三维物体部件分割</strong><br>零件分割是一项具有挑战性的细粒度三维识别任务。给定3D扫描或网格模型，任务是为每个点或面分配零件类别标签(例如，椅腿、杯柄)。<br><strong>实验设计：</strong><br>我们在 ShapeNet 部件数据集上进行评估，该数据集包含16个类别的 16881 个形状，总共标注了 50 个部件。大多数对象类别都标有 2 到 5 个部分。<br>我们将零件分割表示为逐点分类问题。评价指标是基于点的 mIoU（mean Intersection over Union，平均交并比）。比如，对于类别C的每个形状S，要计算形状的 mIoU 值：对于类别C中的每个部件，计算真实和预测之间的 IoU（Intersection over Union，交并比）。如果真实和预测点的并集为空，则将部分 IoU 计数为 1。然后，我们对类别C中所有部分类型的 IoU 进行平均，以获得该形状的 mIoU。为了计算该类别的 mIoU，我们取该类别中所有形状的 mIoU 平均值。<br>我们将我们的分割版本 PointNet (架构图中 Segmentation Network 的修改版本)与两种传统方法 <a href="http://irc.cs.sdu.edu.cn/~yunhai/public_html/papers/cadcg13-lp.pdf">Interactive shape co-segmentation via label propagation</a> 和 <a href="http://web.stanford.edu/~ericyi/papers/part_annotation_16_small.pdf">A scalable active framework for region annotation in 3d shape collections</a> （这两种方法都利用了逐点几何特征和形状之间的对应关系），以及我们自己的 3DCNN 进行了比较。</p><p><strong>实验结果：</strong><br><img src="https://img-blog.csdnimg.cn/20200325173110706.jpg#pic_center" alt="在这里插入图片描述"><br>与 Yi 的方法相比，PointNet 的 mIoU 提高了 $2.3%$ ，并且在大多数类别中都优于 3DCNN。<br><strong>补充实验：</strong><br>还在模拟 Kinect 扫描上进行了实验，以测试这些方法的鲁棒性。对于 ShapeNet 零件数据集中的每一个CAD模型，我们使用 Blensor Kinect<br>Simulator 从六个随机视角生成不完整的点云。并使用相同的网络架构和训练设置对 PointNet 进行完整形状和部分扫描的训练。结果如下：<br><img src="https://img-blog.csdnimg.cn/20200325174951187.jpg#pic_center" alt="在这里插入图片描述"><br>mIoU 只下降了 5.3%。图中可以看出，虽然部分数据颇具挑战性，但我们的预测是合理的。</p><p><strong>5.1.3 场景中的语义分割</strong><br>我们的零件分割网络可以很容易地扩展到场景语义分割，其中点标签是语义对象类，而不是对象零件标签。<br><strong>实验设计</strong><br>我们在Stanford 3D semantic parsing data set 进行了实验，该数据集包含来自 Matterport扫描仪的6个区域(包括271个房间)的3D扫描。扫描中的每个点都用来自13个类别(椅子、桌子、地板、墙壁等加上杂物)中的一个语义标签进行注释。<br>为了准备训练数据，我们首先按房间划分点，然后将样本室分成面积为1m×1m的块。我们训练我们的修改版本的 PointNet 来预测每个块中的每个点类。每个点由关于房间的XYZ、RGB和规格化位置(从0到1)的9维向量表示。在训练时，我们在每个区块中动态随机抽样4096个点。在测试时，我们对所有的点进行测试。我们遵循与 <a href="http://buildingparser.stanford.edu/images/3D_Semantic_Parsing.pdf">3d semantic parsing of large-scale indoor spaces</a> 相同的协议，使用k-折叠策略进行训练和测试。<br>我们将我们的方法与使用手工制作的点特征的基线进行比较。该基线提取了相同的9维局部特征和3个额外的特征：局部点密度、局部曲率和法线，使用标准的 MLP 作为分类器。</p><p><strong>实验结果</strong><br><img src="https://img-blog.csdnimg.cn/20200325214816555.jpg#pic_center" alt="在这里插入图片描述"><br>由表中的定量结果可见，PointNet 方法的性能明显优于基线方法。<br><img src="https://img-blog.csdnimg.cn/2020032521502044.jpg#pic_center" alt="在这里插入图片描述"><br>上图显示了定性的分割结果。我们的网络能够输出平滑的预测，并且对缺失点和遮挡具有很强的鲁棒性。</p><h4 id="5-2-架构设计分析"><a href="#5-2-架构设计分析" class="headerlink" title="5.2. 架构设计分析"></a>5.2. 架构设计分析</h4><p>该部分实验通过对照实验来验证我们的设计选择，还展示了网络超参数的影响。</p><p><strong>5.2.1 与其他顺序不变方法的比较</strong><br>该对照实验仍然使用 ModelNet40 形状分类问题作为比较这些方案的试验台。<br><img src="https://img-blog.csdnimg.cn/20200327102413938.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>我们比较的基线包括 $n×3$ 阵列的未排序和排序的点上的多层感知机、将输入点视为序列的RNN模型和基于对称函数的模型。</p><p>我们实验的对称操作包括最大汇集、平均汇集和基于注意力的加权和。注意力方法类似于 <a href="https://arxiv.org/abs/1511.06391">Order Matters</a> 中的方法，其中从每个点特征预测分数，然后通过计算 Softmax<a href="#refer-anchor-1"><sup>1,</sup></a> <a href="#refer-anchor-1"><sup>2</sup></a> 来对分数进行跨点归一化。然后对归一化分数和点特征计算加权和。如图上所示，最大池化操作以较大的优势实现了最佳性能，这验证了我们的选择。</p><div id="refer-anchor-1"></div><ul><li><p>[1] <a href="https://www.jianshu.com/p/7e200a487916">初探softmax。</a></p><div id="refer-anchor-2"></div></li><li><p>[2] <a href="https://segmentfault.com/a/1190000017320763">为什么是SoftMax？</a></p></li></ul><p><strong>5.2.2 输入和特征转换的有效性</strong><br><img src="https://img-blog.csdnimg.cn/2020032710592961.jpg?type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_10,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>在上表中，我们展示了输入和特性转换(用于对齐)的积极效果。看到最基本的架构已经取得了相当合理的结果，使用输入转换可使性能提升0.8%。<strong>正则化损失</strong>是高维变换工作所必需的。通过<strong>将变换和正则化项结合</strong>，我们获得了最好的性能。</p><p><strong>5.2.3 稳健性测试</strong><br><img src="https://img-blog.csdnimg.cn/20200327111457598.jpg?type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>我们使用与 $5.2.1$ 的最大池化网络相同的架构，输入点被标准化到单位球体中，结果如上图所示。对于缺失点，当有 $50%$ 的缺失点时，采用最远随机输入采样，准确率仅下降 $2.4%$ 和 $3.8%$ 。我们评估了两个模型：一个针对具有 $(x，y，z)$ 坐标的点进行训练；另一个针对 $(x，y，z)$ 加点密度进行训练，即使当 $20%$ 的点异常时，该网络也有 $80%$ 以上的准确率。</p><h4 id="5-3-可视化-PointNet"><a href="#5-3-可视化-PointNet" class="headerlink" title="5.3. 可视化 PointNet"></a>5.3. 可视化 PointNet</h4><p>虽然临界点共同确定给定形状的全局形状特征，但任何落在临界点集和上界形状之间的点云都会提供完全相同的特征。我们对所有数字进行颜色编码，以显示深度信息。<br><img src="https://img-blog.csdnimg.cn/20200327113943390.jpg?type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>上图可视化了一些样本形状 $S$ 的临界点集 $C_S$ 和上界形状 $N_S$ 。这两个形状之间的点集将给出完全相同的全局形状特征 $f(S)$。<br>临界点集 $C_S$ 描述了形状的骨架，上界形状 $N_S$ 表示给出与输入点云 $S$ 相同的全局形状特征 $f(S)$ 的最大可能的点云，这意味着丢失一些非临界点根本不会改变全局形状，反映了 PointNet 的健壮性。</p><h4 id="5-4-时间和空间复杂度分析"><a href="#5-4-时间和空间复杂度分析" class="headerlink" title="5.4. 时间和空间复杂度分析"></a>5.4. 时间和空间复杂度分析<img src="https://img-blog.csdnimg.cn/20200327114901823.jpg?type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_10,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></h4><p>上表总结了 PointNet 的空间(网络中的参数数量)和时间(浮点运算&#x2F;样本)复杂度。<br>我们还将 PointNet 与以前工作中一组有代表性的基于体积和多视图的体系结构进行了比较。<br>虽然 MVCNN 和 Subvolume(3D CNN) 实现了高性能，但 PointNet 在计算成本方面的效率更高(以FLOP&#x2F;样本衡量：效率分别提高141倍和8倍)。此外，就网络中的 $#params$ 而言，PointNet 的空间效率比 MVCNN 高得多(参数减少了17倍)。<br>PointNet 的可扩展性更强，它的空间和时间复杂度在输入点数量上是 $O(N)$ 线性的。然而，由于卷积在计算时间上占主导地位，多视角方法的时间复杂度与图像分辨率成正比增长，而基于体积卷积的方法则随体积大小呈三次曲线增长。<br>根据经验，使用 TensorFlow 上的1080X GPU，PointNet 能够每秒处理超过一百万个点，用于点云分类(约1K对象&#x2F;秒)或语义分割(约2个房间&#x2F;秒)，显示出巨大的实时应用潜力。</p><h3 id="六、结论"><a href="#六、结论" class="headerlink" title="六、结论"></a>六、结论</h3><p>在这项工作中，我们提出了一种新的直接处理点云的深度神经网络 PointNet。我们的网络为许多 3D 识别任务提供了统一的方法，包括对象分类、部件分割和语义分割，同时在标准基准上获得了与最先进水平相当或更好的结果。我们还为理解我们的网络提供理论分析和可视化。</p>]]></content>
    
    
    <categories>
      
      <category>PointNet++</category>
      
    </categories>
    
    
    <tags>
      
      <tag>点云</tag>
      
      <tag>文献</tag>
      
      <tag>深度学习</tag>
      
      <tag>计算机视觉</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>C++ Qt 实现鼠标拖动旋转功能</title>
    <link href="/2020/04/05/C++%20Qt%20%E5%AE%9E%E7%8E%B0%E9%BC%A0%E6%A0%87%E6%8B%96%E5%8A%A8%E6%97%8B%E8%BD%AC%E5%8A%9F%E8%83%BD/"/>
    <url>/2020/04/05/C++%20Qt%20%E5%AE%9E%E7%8E%B0%E9%BC%A0%E6%A0%87%E6%8B%96%E5%8A%A8%E6%97%8B%E8%BD%AC%E5%8A%9F%E8%83%BD/</url>
    
    <content type="html"><![CDATA[<h3 id="零、开始的开始"><a href="#零、开始的开始" class="headerlink" title="零、开始的开始"></a>零、开始的开始</h3><p>这是律盘，看古琴课程时，老师有一个，可以查找各弦散按音位，觉得挺好用，便做了一个。这里只聊聊怎么实现鼠标拖动旋转，可以借鉴到其他开发。<br><img src="https://imgconvert.csdnimg.cn/aHR0cDovL3Zpc3RhcnkuZ2l0ZWUuaW8vaW1nYmVkL2dpZmhvbWVfNDk2eDUxNS5naWY#pic_center" alt="在这里插入图片描述"></p><h3 id="一、实现思路"><a href="#一、实现思路" class="headerlink" title="一、实现思路"></a>一、实现思路</h3><h4 id="1-旋转角度"><a href="#1-旋转角度" class="headerlink" title="1. 旋转角度"></a>1. 旋转角度</h4><p>一般旋转对象函数的输入都是角度，那么怎么获取这个角度呢？<br>鼠标拖动，当然是从鼠标的操作中获取。这个动作中，鼠标有三个状态：按下、拖动、释放，按下的点是旋转开始点（pressPoint），鼠标拖动旋转过程中的鼠标坐标点是当前点（currentPoint），释放时是旋转结束点，也是最后一个当前点。所以获取这 pressPoint 和 currentPoint，再加上旋转中心点（corePoint），就可以求得旋转角度。<br>代码实现如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">//鼠标拖动旋转的角度</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">Disk::setAngle</span><span class="hljs-params">()</span></span>&#123;<br>    <span class="hljs-function">QLineF <span class="hljs-title">lineBegin</span><span class="hljs-params">(corePoint, pressPoint)</span></span>;<br>    <span class="hljs-function">QLineF <span class="hljs-title">lineEnd</span><span class="hljs-params">(corePoint, currentPoint)</span></span>;<br>    mouseAngle = <span class="hljs-number">360</span> - lineBegin.<span class="hljs-built_in">angleTo</span>(lineEnd);<br>    <span class="hljs-keyword">return</span> mouseAngle;<br>&#125;<br></code></pre></td></tr></table></figure><p>为什么是用 360 减去，后面会讲。</p><h4 id="2-旋转方向"><a href="#2-旋转方向" class="headerlink" title="2. 旋转方向"></a>2. 旋转方向</h4><p>对于准确的旋转方向，可以把旋转开始点和旋转结束点看作原点在旋转中心的两个向量，然后通过向量的外积确定旋转方向，具体见 <a href="https://blog.csdn.net/maizousidemao/article/details/105270862">向量乘法与其几何意义</a> ，我们的目的不是获得精确的旋转方向，而且这样会增加软件后台的计算量，所以不选择这种方法。</p><p>使用角度定位法（我自己起的名字），就像时钟一样，是几点就在那个固定的位置，是几度，圆盘也在那个固定的位置。把角度分为过去的（oldAngle）和现在的（currentAngle），还有鼠标拖动旋转的角度（mouseAngle），他们都初始化为 0。</p><h4 id="3-实现旋转"><a href="#3-实现旋转" class="headerlink" title="3. 实现旋转"></a>3. 实现旋转</h4><p>通过角度（currentAngle）获得旋转矩阵，通过旋转矩阵获得旋转后的图片，然后更新图片的显示。代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp">QMatrix rotatematrix;<br>rotatematrix.<span class="hljs-built_in">rotate</span>(currentAngle); <span class="hljs-comment">//通过角度创建旋转矩阵</span><br>QPixmap fitpixmap = pix.<span class="hljs-built_in">transformed</span>(rotatematrix,Qt::SmoothTransformation);<span class="hljs-comment">//旋转</span><br><br><span class="hljs-comment">// 更新背景图</span><br><span class="hljs-keyword">this</span>-&gt;<span class="hljs-built_in">setIcon</span>(fitpixmap);<br><span class="hljs-keyword">this</span>-&gt;<span class="hljs-built_in">setIconSize</span>(<span class="hljs-built_in">QSize</span>(fitpixmap.<span class="hljs-built_in">width</span>(), fitpixmap.<span class="hljs-built_in">height</span>()));<br></code></pre></td></tr></table></figure><h4 id="4-实现流程"><a href="#4-实现流程" class="headerlink" title="4. 实现流程"></a>4. 实现流程</h4><p>对于鼠标的三个状态：按下、拖动、释放（释放后旋转就结束了，所以释放动作并不重要，这里不考虑），<strong>鼠标按下时</strong>，获取 pressPoint 坐标，同时将当前角度 currentAngle（也就是上一次旋转后的位置角度）赋值给旧的角度 oldAngle，代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">//鼠标按下事件</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">Disk::mousePressEvent</span><span class="hljs-params">(QMouseEvent *event)</span></span>&#123;<br>    pressPoint = event-&gt;<span class="hljs-built_in">pos</span>();<br>    oldAngle = currentAngle;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>鼠标拖动时</strong>，获取当前点坐标（currentPoint），然后利用 mouseAngle 和 oldAngle 计算 currentAngle。而 currentAngle &#x3D; oldAngle + mouseAngle，然后再利用 currentAngle 对旋转对象进行定位。<br>到这里你可能会问，oldAngle + mouseAngle，一个方向是加，另一个方向怎么办？<br>所以我用了以下的算法：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">//鼠标移动事件</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">Disk::mouseMoveEvent</span><span class="hljs-params">(QMouseEvent *event)</span></span>&#123;<br>    currentPoint = event-&gt;<span class="hljs-built_in">pos</span>();<br><span class="hljs-keyword">if</span>(oldAngle &gt; <span class="hljs-number">360</span>)&#123;<br>oldAngle = oldAngle % <span class="hljs-number">360</span>;<br>&#125;<br><br>currentAngle = oldAngle + <span class="hljs-built_in">setAngle</span>(); <span class="hljs-comment">//setAngle()返回mouseAngle </span><br><br><span class="hljs-keyword">if</span>(currentAngle &gt; <span class="hljs-number">360</span>)&#123;<br>currentAngle = currentAngle % <span class="hljs-number">360</span>;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p> oldAngle 和 currentAngle 都对 360 取余，保证他们小于等于 360，否则会出现跳变。当顺时针转动，currentAngle &#x3D; oldAngle + mouseAngle 很容易理解，逆时针时本应该是 currentAngle &#x3D; oldAngle - mouseAngle，这就涉及到 “1. 旋转角度” 中为什么要用 360 减去了。lineBegin.angleTo(lineEnd) 函数测量角度是从 lineBegin 到 lineEnd 沿逆时针方向测量的，示意图如下：<br><img src="https://img-blog.csdnimg.cn/20200404222131583.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>我选择了使顺时针理解容易，且 currentAngle 已初始化为 0 ，所以用 360 减去测量角度。如果鼠标逆时针拖动，比如图中右边的情况，mouseAngle &#x3D; 307，oldAngle &#x3D; 77，则 currentAngle &#x3D; oldAngle + mouseAngle &#x3D; 384，然后对 360 取余，正好是 24，最后利用这个角度进行旋转，一次操作结束。</p><h3 id="二、完整代码"><a href="#二、完整代码" class="headerlink" title="二、完整代码"></a>二、完整代码</h3><p><a href="https://github.com/Holsey/rotateDisk"> https://github.com/Holsey/rotateDisk </a></p><p>现在该软件为 2.0 版本，添加了十二律、五音、简谱、西音、工尺对应查找功能，如下：<br><img src="https://img-blog.csdnimg.cn/20200404231025262.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haXpvdXNpZGVtYW8=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>如果你想使用这个软件，请联系我，QQ：1055311345。</p>]]></content>
    
    
    <categories>
      
      <category>项目</category>
      
    </categories>
    
    
    <tags>
      
      <tag>项目</tag>
      
      <tag>Qt</tag>
      
      <tag>C++</tag>
      
      <tag>面向对象</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python爬虫实现isbn查询书籍详细信息</title>
    <link href="/2020/03/30/Python%E7%88%AC%E8%99%AB%E5%AE%9E%E7%8E%B0isbn%E6%9F%A5%E8%AF%A2%E4%B9%A6%E7%B1%8D%E8%AF%A6%E7%BB%86%E4%BF%A1%E6%81%AF/"/>
    <url>/2020/03/30/Python%E7%88%AC%E8%99%AB%E5%AE%9E%E7%8E%B0isbn%E6%9F%A5%E8%AF%A2%E4%B9%A6%E7%B1%8D%E8%AF%A6%E7%BB%86%E4%BF%A1%E6%81%AF/</url>
    
    <content type="html"><![CDATA[<h3 id="0-开始的开始"><a href="#0-开始的开始" class="headerlink" title="0. 开始的开始"></a>0. 开始的开始</h3><p>一直想做一个图书漂流软件，最近入手（入坑）了微信小程序，添加图书时需要用到isbn查询书籍信息的API（不用也可以，但用户会非常麻烦，强迫症晚期的我又跳入了isbn查询API的坑），但发现别人的API都很贵，豆瓣也收回了API的使用权，估计是要收费了。<br>所以，与其在坑里苦苦挣扎，不如。。。。再挖一个更大的坑，自己做一个。。。</p><h3 id="1-开始"><a href="#1-开始" class="headerlink" title="1. 开始"></a>1. 开始</h3><p>首先打算用python写个爬虫（能力与知识有限，现在只能想到这个办法，如前辈们有更好的办法，请砸过来）。<br>搜索了几个可以用isbn查书籍信息的网站，最后还是选择了豆瓣。<br>豆瓣isbn查书籍信息的流程为：</p><ol><li>打开豆瓣读书的首页<br><img src="https://img-blog.csdnimg.cn/20191013134450510.png#pic_center" alt="在这里插入图片描述"></li><li>在搜索框输入isbn码<br><img src="https://img-blog.csdnimg.cn/20191013134508154.png#pic_center" alt="在这里插入图片描述"></li><li>回车或点击小放大镜，书籍的信息出来了<br><img src="https://img-blog.csdnimg.cn/20191013134545522.png#pic_center" alt="在这里插入图片描述"></li></ol><p>本来想的很好，就这样一路闪电带火花把核心代码写了，然而，总有不尽人意的地方。就在第3步，本来打算在这里把信息给爬了，却发现爬回来是空的，也不知道什么原因（查html代码，发现有一级标签id为root，可能豆瓣设置了权限，猜的，具体原因不知道）。</p><h3 id="2-爬取内容"><a href="#2-爬取内容" class="headerlink" title="2. 爬取内容"></a>2. 爬取内容</h3><p>虽然人生不尽人意，但还是要走下去。在第3步的页面，点击书名或图片会出来更详细的信息。<br><img src="https://img-blog.csdnimg.cn/20191013142023353.png#pic_center" alt="在这里插入图片描述"><br>果然，这里的信息可以爬取，要什么有什么。</p><h4 id="2-1-获取书籍信息页面的链接地址"><a href="#2-1-获取书籍信息页面的链接地址" class="headerlink" title="2.1 获取书籍信息页面的链接地址"></a>2.1 获取书籍信息页面的链接地址</h4><p><strong>思路：</strong><br>打开豆瓣读书首页，模拟浏览器填写isbn码，进行搜索，跳转到搜索结果页面，读取a标签href链接，即书籍信息页面的链接地址。<br>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">isbn_search</span>(<span class="hljs-params">isbn</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        输入：isbn</span><br><span class="hljs-string">        输出：豆瓣搜索结果的书籍链接</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 创建浏览器对象</span><br>    browser = webdriver.PhantomJS()<br>    <span class="hljs-comment"># 请求网址</span><br>    browser.get(<span class="hljs-string">&quot;https://book.douban.com/subject_search?search_text=&quot;</span> + isbn + <span class="hljs-string">&quot;&amp;cat=1001&quot;</span>)<br>    <span class="hljs-comment"># 解析网页信息</span><br>    soup = BeautifulSoup(browser.page_source, <span class="hljs-string">&quot;lxml&quot;</span>)<br>    <span class="hljs-comment"># 读取标签内容</span><br>    tags = soup.select(<span class="hljs-string">&quot;#root &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; a&quot;</span>)<br>    <span class="hljs-comment"># 正则查找href链接</span><br>    link_list = re.findall(<span class="hljs-string">r&quot;(?&lt;=href=\&quot;).+?(?=\&quot;)|(?&lt;=href=\&#x27;).+?(?=\&#x27;)&quot;</span>, <span class="hljs-built_in">str</span>(tags[<span class="hljs-number">0</span>]))<br>    <span class="hljs-comment"># 关闭浏览器</span><br>    browser.close()<br>    <span class="hljs-keyword">return</span> link_list[<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure><h4 id="2-2-爬取书籍详细信息"><a href="#2-2-爬取书籍详细信息" class="headerlink" title="2.2 爬取书籍详细信息"></a>2.2 爬取书籍详细信息</h4><p><strong>思路：</strong><br>打开2.1获取的页面，找到书籍信息块代码，爬回并清洗，得到需要的信息。<br>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">book_info</span>(<span class="hljs-params">douban_link</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        输入：豆瓣书籍链接</span><br><span class="hljs-string">        输出：书籍信息</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    headers = &#123;<span class="hljs-string">&#x27;User-Agent&#x27;</span>:<span class="hljs-string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) \</span><br><span class="hljs-string">        AppleWebKit/537.36 (KHTML, like Gecko) \</span><br><span class="hljs-string">        Chrome/80.0.3987.149 Safari/537.36&#x27;</span>&#125;<br>    <span class="hljs-comment"># 请求网址</span><br>    g=requests.get(douban_link,headers=headers)<br>    <span class="hljs-comment"># 解析网页信息</span><br>    soup=BeautifulSoup(g.content,<span class="hljs-string">&quot;lxml&quot;</span>)<br>    <span class="hljs-comment"># 由于书名和其他信息不在一起，单独处理书名</span><br>    title = <span class="hljs-string">&quot;书名： 《&quot;</span> + re.sub(<span class="hljs-string">&#x27;[\f\n\r\t\v]&#x27;</span>,<span class="hljs-string">&#x27;&#x27;</span>,re.sub(<span class="hljs-string">&#x27;&lt;([^&gt;]+?)&gt;&#x27;</span>,<span class="hljs-string">&#x27;&#x27;</span>,<span class="hljs-built_in">str</span>((soup.select(<span class="hljs-string">&quot;#wrapper &gt; h1 &gt; span&quot;</span>))[<span class="hljs-number">0</span>]))) + <span class="hljs-string">&quot;》&quot;</span><br>    <span class="hljs-comment"># 存储书籍信息</span><br>    infos = [title]<br>    <span class="hljs-comment"># 返回特定区域的html代码块</span><br>    span_list = soup.findChild(<span class="hljs-string">&#x27;div&#x27;</span>,&#123;<span class="hljs-string">&#x27;id&#x27;</span>:<span class="hljs-string">&#x27;info&#x27;</span>&#125;)<br><br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> <span class="hljs-built_in">str</span>(span_list).split(<span class="hljs-string">&#x27;&lt;br/&gt;&#x27;</span>): <span class="hljs-comment"># 将信息按项目分割,每个item是一个信息项</span><br>        <span class="hljs-comment"># 用两次正则，一次去掉多余html代码，一次去掉制表换行等字符</span><br>        <span class="hljs-comment"># .split(&quot;:&quot;)以：分割每个信息项目</span><br>        info_item = re.sub(<span class="hljs-string">&#x27;[\f\n\r\t\v]&#x27;</span>,<span class="hljs-string">&#x27;&#x27;</span>,re.sub(<span class="hljs-string">&#x27;&lt;([^&gt;]+?)&gt;&#x27;</span>,<span class="hljs-string">&#x27;&#x27;</span>,item)).split(<span class="hljs-string">&quot;:&quot;</span>)<br>        info_temp = [] <span class="hljs-comment"># 存放以“/”分隔的item</span><br>        <span class="hljs-keyword">for</span> info_item_item <span class="hljs-keyword">in</span> info_item:<br>            sprit = info_item_item.partition(<span class="hljs-string">&quot;/&quot;</span>) <span class="hljs-comment"># 以“/”分隔info_item_item</span><br>            <span class="hljs-keyword">for</span> sprit_item <span class="hljs-keyword">in</span> sprit:<br>                info_temp += sprit_item.partition(<span class="hljs-string">&quot;]&quot;</span>) <span class="hljs-comment"># 以“/”分隔sprit_item, 并将处理后的列表合并</span><br><br>        <span class="hljs-comment"># info_temp 存储单项信息的列表</span><br>        <span class="hljs-comment"># 以单项信息为操作单位去除空格</span><br>        <span class="hljs-comment"># temp_list 存储去空格处理后的单项信息</span><br>        temp_list = []<br>        <span class="hljs-keyword">for</span> temp <span class="hljs-keyword">in</span> info_temp:<br>            ddd=temp.strip() <span class="hljs-comment"># 去掉字符左右的空格</span><br>            <span class="hljs-comment"># 过滤掉因去掉空格而产生的空字符串</span><br>            <span class="hljs-keyword">if</span> ddd != <span class="hljs-string">&#x27;&#x27;</span>:<br>                temp_list.append(ddd)<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-comment"># 在书籍属性后加“：”</span><br>            info = temp_list[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;: &#x27;</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(temp_list)):<br>                info += temp_list[i] <span class="hljs-comment"># 拼接每个信息项目</span><br><br>        <span class="hljs-comment"># 判断temp_list是否为空，为空则info为错误值，不存入infos</span><br>        <span class="hljs-keyword">if</span> temp_list:<br>            <span class="hljs-keyword">pass</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">continue</span> <br><br>        infos.append(info)<br><br>    <span class="hljs-keyword">return</span> infos<br></code></pre></td></tr></table></figure><h3 id="3-效果"><a href="#3-效果" class="headerlink" title="3. 效果"></a>3. 效果</h3><p><img src="https://img-blog.csdnimg.cn/20191014112041629.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20191014112452864.png" alt="在这里插入图片描述"><br>这里使用PhantomJS浏览器，但会报UserWarning，Selenium最新版不支持PhantomJS了，我用的Selenium 3.141.0，UserWarning建议使用谷歌或火狐浏览器的无头模式，但我没成功，如有大佬成功了希望交流一下。</p><h3 id="4-完整代码下载"><a href="#4-完整代码下载" class="headerlink" title="4. 完整代码下载"></a>4. 完整代码下载</h3><p><a href="https://github.com/Holsey/isbn_search">isbn查询书籍详细信息</a></p><blockquote><p>仅供学习，勿作商用，如有违反，后果自负。<br>不知道豆瓣有一天会不会把这个方法给ban掉。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>项目</tag>
      
      <tag>Python</tag>
      
      <tag>爬虫</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Dpkg：错误：另外一个进程已经为 Dpkg 状态数据库 加锁</title>
    <link href="/2020/03/29/dpkg%EF%BC%9A%E9%94%99%E8%AF%AF%EF%BC%9A%E5%8F%A6%E5%A4%96%E4%B8%80%E4%B8%AA%E8%BF%9B%E7%A8%8B%E5%B7%B2%E7%BB%8F%E4%B8%BA%20dpkg%20%E7%8A%B6%E6%80%81%E6%95%B0%E6%8D%AE%E5%BA%93%20%E5%8A%A0%E9%94%81/"/>
    <url>/2020/03/29/dpkg%EF%BC%9A%E9%94%99%E8%AF%AF%EF%BC%9A%E5%8F%A6%E5%A4%96%E4%B8%80%E4%B8%AA%E8%BF%9B%E7%A8%8B%E5%B7%B2%E7%BB%8F%E4%B8%BA%20dpkg%20%E7%8A%B6%E6%80%81%E6%95%B0%E6%8D%AE%E5%BA%93%20%E5%8A%A0%E9%94%81/</url>
    
    <content type="html"><![CDATA[<h3 id="一、问题描述"><a href="#一、问题描述" class="headerlink" title="一、问题描述"></a><strong>一、问题描述</strong></h3><p>　　平时喜欢边听歌边敲代码（有种拯救世界的感觉），windows时一直用网易云，换了linux非常不方便，所以想给我的ubuntu（16.04）装一个。去官网找了一下，还真有linux版的，还特别标明是ubuntu 16.04（64位），良心软件啊，接下来就是载下来按部就班安装了。<br>　　载下来是.deb格式的，需要用以下命令：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">dpkg -<span class="hljs-selector-tag">i</span> 软件名<span class="hljs-selector-class">.deb</span><br></code></pre></td></tr></table></figure><p>　　开始一切都挺顺利，然而命运终于还是对我下手了。<br>　　<img src="https://vistary.gitee.io/imgbed/images/dpkg_locked.jpg" alt="这里写图片描述"></p><h3 id="二、问题分析"><a href="#二、问题分析" class="headerlink" title="二、问题分析"></a><strong>二、问题分析</strong></h3><p>　　0. 注意，不是权限问题，我已经在root下了。<br>　　1. 说是“另外一个进程”，首先看了一下进程。</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">ps</span> -<span class="hljs-keyword">a</span><br><span class="hljs-keyword">ps</span> -A<br><span class="hljs-keyword">ps</span> -aux<br><span class="hljs-keyword">ps</span> -aux | <span class="hljs-keyword">grep</span> dpkg<br></code></pre></td></tr></table></figure><p>　　试了各种命令，没有找到关于dpkg的进程。<br>　　（第一次向命运的抗争以失败告终）<br>　　2. 既然找不到心中的那个进程（我知道你一定在那，就是找不到你，救不出我的dpkg），重启吧，一切重新开始。<br>　　。。。。。<br>　　开机后竟然可以了，可能是那个进程已经kill掉了，放回了我的dpkg。<br>　　好了，继续安装网易云。。。<br>　　不过命运又皮了一下，有未能满足的依赖关系，解决办法看这篇文章，<a href="https://blog.csdn.net/maizousidemao/article/details/82109038"><br>linux安装软件报错：有未能满足的依赖关系</a></p><h3 id="三、解决方法"><a href="#三、解决方法" class="headerlink" title="三、解决方法"></a><strong>三、解决方法</strong></h3><p>　　后来百度了一下，有两种方法可以解决这个问题：<br>　　方法一：重启系统，很方便。<br>　　方法二：删除dpkg下的lock文件，有人说这样做可能会让系统挂掉，试了一下，我的没问题（不保证你的也没问题啊，毕竟每个ubuntu脾气还是不一样的）。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">rm  <span class="hljs-regexp">/var/</span>lib<span class="hljs-regexp">/dpkg/</span>lock<br></code></pre></td></tr></table></figure><h3 id="四、小结"><a href="#四、小结" class="headerlink" title="四、小结"></a><strong>四、小结</strong></h3><p>　　1. 进程占用问题，kill那个进程或重启系统。<br>　　2. 熟悉linux的文件系统。</p>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
      <tag>Ubuntu</tag>
      
      <tag>debug</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ubuntu16.04虚拟机桥接模式配置静态IP</title>
    <link href="/2020/03/29/ubuntu16.04%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%E9%85%8D%E7%BD%AE%E9%9D%99%E6%80%81IP/"/>
    <url>/2020/03/29/ubuntu16.04%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%E9%85%8D%E7%BD%AE%E9%9D%99%E6%80%81IP/</url>
    
    <content type="html"><![CDATA[<p>本教程仅供学习，如急需解决问题，仅供参考。</p><p>在虚拟机安装好ubuntu16.04后，发现只有NAT模式可以上网，而桥接模式不能上网，经过一番摸索总结方法如下：</p><h3 id="一、配置IP地址、默认网关、子网掩码"><a href="#一、配置IP地址、默认网关、子网掩码" class="headerlink" title="一、配置IP地址、默认网关、子网掩码"></a>一、配置IP地址、默认网关、子网掩码</h3><p>命令：</p><p> <strong>1. ifconfig</strong>(查看网卡信息)<br><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTgwMTIwMTc1NjE2NjU0?x-oss-process=image/format,png" alt="这里写图片描述"><br>有两块网卡，配置ens33（以太网）<br>我的是配置好的，你的显示可能和这个不一样，这一步只是看以太网卡的名字，配置时会用到</p><p>接下来切换用户，提高权限<br><strong>2. sudo -s</strong> (进入管理员模式，修改配置文件需要较高权限)<br><strong>3. vi &#x2F;etc&#x2F;network&#x2F;interfaces</strong> (打开并编辑配置文件)<br><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTgwMTIwMTgwMTA1NDI1?x-oss-process=image/format,png" alt="这里写图片描述"><br>打开文件后，编辑内容使如下图：<br><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTgwMTIwMTc1MDU0MjU0?x-oss-process=image/format,png" alt="这里写图片描述"><br>配置说明：<br><strong>auto lo</strong><br><strong>iface lo inet loopback</strong></p><p><strong>auto ens33</strong>（ens33为以太网卡，根据实际名称填写）<br><strong>iface ens33 inet static</strong><br><strong>address  &nbsp;&nbsp;&nbsp; 192.168.1.8</strong>（IP地址，要和物理机在同一网段，且不要和局域网内其他设备IP冲突，查看方法见下）<br><strong>gateway &nbsp; 192.168.1.1</strong>（默认网关，和物理机一样）<br><strong>netmask &nbsp; 255.255.255.0</strong>（子网掩码，和物理机一样）</p><p>查看物理机IP等信息方法：</p><ol><li>Windows + R 快捷键打开“运行”对话框</li><li>输入CMD，点确定打开CMD命令行</li><li>键入ipconfig，敲回车</li><li>查找信息，有多块网卡，还有两块是虚拟机的网卡，不要看错<br><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTgwMTIwMTkwOTQ1MTc5?x-oss-process=image/format,png" alt="这里写图片描述"></li></ol><p>查看同局域网内其他设备IP方法：</p><ol><li>Windows + R 快捷键打开“运行”对话框</li><li>输入CMD，点确定打开CMD命令行</li><li>键入arp &nbsp; -a，敲回车</li></ol><p>编辑完配置文件，保存退出，如第2步没切换为管理员，这一步会禁止保存，不过也有解决办法，但太繁琐，有兴趣可以自行查阅。</p><h3 id="二、配置永久DNS"><a href="#二、配置永久DNS" class="headerlink" title="二、配置永久DNS"></a>二、配置永久DNS</h3><p>命令：<br> <strong>vi &#x2F;etc&#x2F;resolvconf&#x2F;resolv.conf.d&#x2F;base</strong>（这个文件默认是空的）<br> <img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTgwMTIwMTkxNDA2OTAz?x-oss-process=image/format,png" alt="这里写图片描述"><br> 输入上面所查询的物理机DNS服务器IP，如下图：<br> <img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTgwMTIwMTkxMjQ4MjM3?x-oss-process=image/format,png" alt="这里写图片描述"><br>保存退出</p><h3 id="三、重启网络服务"><a href="#三、重启网络服务" class="headerlink" title="三、重启网络服务"></a>三、重启网络服务</h3><p>命令：<br><strong>service network restart</strong><br>这一步我的无法重启，也没找到有效的解决办法，如果你有好的解决办法，可以联系我，非常感谢。<br><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTgwMTIwMTkxNTM0ODI1?x-oss-process=image/format,png" alt="这里写图片描述"><br>这一步可以直接重启系统，命令：<br><strong>reboot</strong></p><h3 id="四、检查"><a href="#四、检查" class="headerlink" title="四、检查"></a>四、检查</h3><p>重启后，可以ping一下外网，看是否可以ping通<br>如ping不通，建议检查一下所修改配置文件</p><ol><li>看是否有个别字母错误，linux对大小写敏感</li><li>IP网段，DNS，子网掩码，默认网关是否和物理机一样</li><li>如还不行，可以重装系统，再次配置，多次尝试练手可以加深印象</li></ol>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
      <tag>Ubuntu</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Terminator安装、美化、使用及闪退解决</title>
    <link href="/2020/03/29/terminator%E5%AE%89%E8%A3%85%E3%80%81%E7%BE%8E%E5%8C%96%E3%80%81%E4%BD%BF%E7%94%A8%E5%8F%8A%E9%97%AA%E9%80%80%E8%A7%A3%E5%86%B3/"/>
    <url>/2020/03/29/terminator%E5%AE%89%E8%A3%85%E3%80%81%E7%BE%8E%E5%8C%96%E3%80%81%E4%BD%BF%E7%94%A8%E5%8F%8A%E9%97%AA%E9%80%80%E8%A7%A3%E5%86%B3/</url>
    
    <content type="html"><![CDATA[<p>选择 terminator 主要是看中了它优秀的分屏功能。</p><h3 id="一、安装-terminator"><a href="#一、安装-terminator" class="headerlink" title="一、安装 terminator"></a>一、安装 terminator</h3><ol><li>添加仓库&#x2F;软件源</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo add-apt-repository ppa:gnome-terminator<br></code></pre></td></tr></table></figure><ol start="2"><li>更新源</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt update<br></code></pre></td></tr></table></figure><ol start="3"><li>安装 terminator</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt install terminator<br></code></pre></td></tr></table></figure><h3 id="二、美化-terminator-界面"><a href="#二、美化-terminator-界面" class="headerlink" title="二、美化 terminator 界面"></a>二、美化 terminator 界面</h3><p>这是初始界面。<br><img src="https://img-blog.csdnimg.cn/2019121322374167.png" alt="在这里插入图片描述"><br>通过修改配置文件美化窗口。<br>在终端输入以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/.config/terminator/ <br>sudo gedit config<br></code></pre></td></tr></table></figure><p>注意！第一次进入~&#x2F;.config&#x2F;terminator&#x2F;目录时，config文件是不存在的，要通过以下步骤找到config</p><ol><li>在 terminator 黑色背景上右键</li><li>单击 Preferences (首选项)<br><img src="https://img-blog.csdnimg.cn/2019121322541367.png" alt="在这里插入图片描述"></li><li>选择 Profiles (布局)，按照图中标记选择，default 处可以自定义名称。</li></ol><p><img src="https://img-blog.csdnimg.cn/20191213225543183.png" alt="在这里插入图片描述"><br>4. 按照上面的步骤找到 config，进行编辑。</p><p>我的 config 内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs bash">[global_config]<br>  enabled_plugins = CustomCommandsMenu, LaunchpadCodeURLHandler, APTURLHandler, LaunchpadBugURLHandler<br>  handle_size = -3<br>  inactive_color_offset = 1.0<br>  suppress_multiple_term_dialog = True<br>  title_transmit_bg_color = <span class="hljs-string">&quot;#3e3838&quot;</span><br>  title_transmit_fg_color = <span class="hljs-string">&quot;#000000&quot;</span><br>[keybindings]<br>[layouts]<br>  [[default]]<br>    [[[child1]]]<br>      parent = window0<br>      profile = default<br>      <span class="hljs-built_in">type</span> = Terminal<br>    [[[window0]]]<br>      parent = <span class="hljs-string">&quot;&quot;</span><br>      size = 925, 570<br>      <span class="hljs-built_in">type</span> = Window<br>[plugins]<br>[profiles]<br>  [[default]]<br>    background_color = <span class="hljs-string">&quot;#1e1e1e&quot;</span><br>    background_darkness = 0.8<br>    background_image = None<br>    background_type = transparent<br>    cursor_color = <span class="hljs-string">&quot;#e8e8e8&quot;</span><br>    cursor_shape = ibeam<br>    font = Ubuntu Mono 14<br>    foreground_color = <span class="hljs-string">&quot;#e8e8e8&quot;</span><br>    palette = <span class="hljs-string">&quot;#292424:#5a8e1c:#2d5f5f:#cdcd00:#1e90ff:#cd00cd:#00cdcd:#d6d9d4:#4c4c4c:#868e09:#00ff00:#ffff00:#4682b4:#ff00ff:#00ffff:#ffffff&quot;</span><br>    scroll_background = False<br>    scrollback_lines = 3000<br>    show_titlebar = False<br>    use_system_font = False<br></code></pre></td></tr></table></figure><p>美化后的 terminator<br><img src="https://img-blog.csdnimg.cn/20191213231047704.png" alt="在这里插入图片描述"></p><h3 id="三、常用快捷键"><a href="#三、常用快捷键" class="headerlink" title="三、常用快捷键"></a>三、常用快捷键</h3><p><kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>O</kbd> 水平分割终端（分成上下两个窗口）<br><kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>E</kbd> 垂直分割终端（分成左右两个窗口）<br><kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>W</kbd> 关闭当前终端<br><kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>X</kbd>  放大（还原）当前终端<br><kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>G</kbd> 清屏<br><kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>Right</kbd>&#x2F;<kbd>Left</kbd> 在垂直分割的终端中将分割条向右&#x2F;左移动<br><kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>S</kbd> 隐藏&#x2F;显示滚动条<br><kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>Q</kbd> 关闭所有终端（退出程序）<br><kbd>F11</kbd> 全屏</p><h3 id="四、打不开或闪退问题"><a href="#四、打不开或闪退问题" class="headerlink" title="四、打不开或闪退问题"></a>四、打不开或闪退问题</h3><p>一般发生这种问题的电脑都是默认 Python3.x 版本的，而 terminator 是基于python2开发的，所以会出问题。<br>如下方法解决：<br>终端输入：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo gedit /usr/share/terminator/terminator<br></code></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20191213233134522.png" alt="在这里插入图片描述"><br>将第一行的将第一行的 <code>#!/usr/bin/python </code>修改为 <code>#!/usr/bin/python2</code><br>然后 terminator 就能打开了，亲测可用。</p>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
      <tag>terminal</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ubuntu16.04更新源详细操作步骤</title>
    <link href="/2020/03/29/ubuntu16.04%20%E6%9B%B4%E6%96%B0%E6%BA%90%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4/"/>
    <url>/2020/03/29/ubuntu16.04%20%E6%9B%B4%E6%96%B0%E6%BA%90%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4/</url>
    
    <content type="html"><![CDATA[<p>由于linux系统自带的镜像源都在国外，国内用户下载或更新软件会比较慢，有时是非常慢，所以国内某些机构，如大学，研究院所，就在国内建了linux的镜像源服务器供国内linux用户使用，而我们要使用这些源，就要更改自己linux系统的更新源配置文件，接下来详述更新源操作步骤。</p><h3 id="1-首先我们要找到国内的镜像源路径"><a href="#1-首先我们要找到国内的镜像源路径" class="headerlink" title="1. 首先我们要找到国内的镜像源路径"></a><strong>1. 首先我们要找到国内的镜像源路径</strong></h3><p> 我选择了清华的镜像源，链接如下：<br><a href="https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/">清华镜像源</a><br> 打开链接如下图：<br> <img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTgwMTIyMTI0ODAyMDc0?x-oss-process=image/format,png" alt="这里写图片描述"><br>接下来按图中提示操作即可。<br>也可以自己搜索其他的镜像源。</p><h3 id="2-备份系统自带更新源配置文件"><a href="#2-备份系统自带更新源配置文件" class="headerlink" title="2. 备份系统自带更新源配置文件"></a><strong>2. 备份系统自带更新源配置文件</strong></h3><p>打开终端切换到管理员（修改配置文件需要较高权限，如不切换也可以在每条命令前加sudo，不过个人感觉有点麻烦），进入 <strong>&#x2F;etc&#x2F;apt</strong> 目录，找到 <strong>sources.list</strong> 文件，进行备份，如下图：<br><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTgwMTIyMTMwMDE4NDEz?x-oss-process=image/format,png" alt="这里写图片描述"><br>也可以直接用命令：<strong>cp&nbsp; &#x2F;etc&#x2F;apt&#x2F;sources.list&nbsp; &#x2F;etc&#x2F;apt&#x2F;sources.list.backup</strong> ，则不用切换目录直接备份。</p><h3 id="3-修改配置文件sources-list内容"><a href="#3-修改配置文件sources-list内容" class="headerlink" title="3.修改配置文件sources.list内容"></a><strong>3.修改配置文件sources.list内容</strong></h3><p>输入命令：<strong>gedit &nbsp; sources.list</strong> 打开文件，把文件内容全部删除，再把更新源路径粘贴进来。<br><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTgwMTIyMTMwODU5OTI1?x-oss-process=image/format,png" alt="这里写图片描述"></p><p>粘贴后如下图：<br><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTgwMTIyMTMxMTI5NDI3?x-oss-process=image/format,png" alt="这里写图片描述"><br>保存，退出。</p><h3 id="4-更新源"><a href="#4-更新源" class="headerlink" title="4. 更新源"></a><strong>4. 更新源</strong></h3><p>输入命令：<strong>apt &nbsp; update</strong> （也可以用apt-get&nbsp;update，<a href="https://blog.csdn.net/maizousidemao/article/details/79859669">apt与apt-get的区别</a>）</p><p>开始更新源<br><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTgwMTIyMTMxNDM1MjMy?x-oss-process=image/format,png" alt="这里写图片描述"></p><p>更新完成<br><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTgwMTIyMTMxNTI1MjUz?x-oss-process=image/format,png" alt="这里写图片描述"><br>我用了1分1秒，这一步根据网速不同，消耗时间也不同，有时特别慢，要耐心等待，直到出现“完成”。</p>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
      <tag>Ubuntu</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>windows下OpenCV的安装部署详细教程</title>
    <link href="/2020/03/28/windows%E4%B8%8BOpenCV%E7%9A%84%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B/"/>
    <url>/2020/03/28/windows%E4%B8%8BOpenCV%E7%9A%84%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h3 id="零、简介"><a href="#零、简介" class="headerlink" title="零、简介"></a><strong>零、简介</strong></h3><p>　　OpenCV的全称是Open Source Computer Vision Library，是一个跨平台的计算机视觉库。OpenCV是由英特尔公司发起并参与开发，以BSD许可证授权发行，可以在商业和研究领域中免费使用。OpenCV可用于开发实时的图像处理、计算机视觉以及模式识别程序。该程序库也可以使用英特尔公司的IPP进行加速处理。<br>　　OpenCV用C++语言编写，它的主要接口也是C++语言，但是依然保留了大量的C语言接口。该库也有大量的Python、Java and MATLAB&#x2F;OCTAVE（版本2.5）的接口。这些语言的API接口函数可以通过在线文档获得。如今也提供对于C#、Ch、Ruby、GO的支持。<br>　　简单理解OpenCV就是一个库，是一个SDK，一个开发包，解压后直接用就可以。<br>　　由于OpenCV网站及软件都更新了，博客也小小改了一下，<br><a href="https://www.jianshu.com/p/71d7bc4e0291">windows 下OpenCV的安装部署详细教程</a></p><h3 id="一、下载OpenCV"><a href="#一、下载OpenCV" class="headerlink" title="一、下载OpenCV"></a><strong>一、下载OpenCV</strong></h3><p>　　到<a href="https://opencv.org/">OpenCV官网</a>下载你需要的版本。<br>　　点击RELEASES（发布）</p><p><img src="https://vistary.gitee.io/imgbed/images/opencv_install/20180807092613500.jpg" alt="这里写图片描述"></p><p>由于OpenCV支持好多平台，比如Windows, Android, Maemo, FreeBSD, OpenBSD, iOS, Linux和Mac OS，一般初学者都是用windows，所以在这里下载Win pack<br><img src="https://vistary.gitee.io/imgbed/images/opencv_install/20180807092814390.jpg" alt="这里写图片描述"></p><p>点击Win pack 后跳出下面界面，等待5s自动下载。<br><img src="https://vistary.gitee.io/imgbed/images/opencv_install/20180807093013393.jpg" alt="这里写图片描述"></p><p>下载后是这样的<br><img src="https://vistary.gitee.io/imgbed/images/opencv_install/20180807100920492.jpg" alt="这里写图片描述"><br>然后双击他，解压，就是大佬们说的安装，实质就是解压一下，解压完出来一个文件夹，其他什么也没发生。你把这个文件夹放在哪都行，不过你要记住他在哪。<br><img src="https://vistary.gitee.io/imgbed/images/opencv_install/20180807101015789.jpg" alt="这里写图片描述"><br>正在解压<br><img src="https://vistary.gitee.io/imgbed/images/opencv_install/20180807101038807.jpg" alt="这里写图片描述"><br>解压完打开文件夹是这样的<br><img src="https://vistary.gitee.io/imgbed/images/opencv_install/20180807101236346.jpg" alt="这里写图片描述"><br>其中build是OpenCV使用时要用到的一些库文件，而sources中则是OpenCV官方为我们提供的一些demo示例源码</p><h3 id="二、配置环境变量"><a href="#二、配置环境变量" class="headerlink" title="二、配置环境变量"></a><strong>二、配置环境变量</strong></h3><p>　　把OpenCV文件夹放好地方后，依次选择计算机—&gt;属性—&gt;高级系统设置—&gt;环境变量，找到Path变量，选中并点击编辑，然后新建把你的OpenCV执行文件的路径填进去，然后一路点确定，这样环境变量就配置完了。<br><img src="https://vistary.gitee.io/imgbed/images/opencv_install/20180807101427956.jpg" alt="这里写图片描述"><br>OpenCV执行文件的路径这样找：<br>找到你解压好的OpenCV文件夹，依次选择build—&gt;x64—&gt;vc15—&gt;bin，<br>然后是这样的<br><img src="https://vistary.gitee.io/imgbed/images/opencv_install/20180807102134895.jpg" alt="这里写图片描述"><br>这个路径就是我的OpenCV执行文件的路径，你的应该和我的差不多吧。<br>这里注意，如果你下载的是OpenCV2.x版本，选择build后，还需要选择x86或x64，然后是vc12（为什么不是vc10或vc11，一般都是选最新的），其他步骤大同小异。</p><h3 id="三、部署OpenCV"><a href="#三、部署OpenCV" class="headerlink" title="三、部署OpenCV"></a><strong>三、部署OpenCV</strong></h3><p>　　前面说了，OpenCV是一个SDK，得使用工具开发它，比如Visual Studio（当然有些大佬只用记事本或神一样的Vim），接下来就是在Visual Studio中部署OpenCV了。</p><h4 id="0-安装Visual-Studio"><a href="#0-安装Visual-Studio" class="headerlink" title="0. 安装Visual Studio"></a><strong>0. 安装Visual Studio</strong></h4><p>　　因为主题是OpenCV，这个这里不讲了，请自行Google。</p><h4 id="1-打开Visual-Studio，新建工程"><a href="#1-打开Visual-Studio，新建工程" class="headerlink" title="1. 打开Visual Studio，新建工程"></a><strong>1. 打开Visual Studio，新建工程</strong></h4><p>　　初学者最好是建一个控制台工程，没有其他问题的干扰。</p><h4 id="2-添加包含目录"><a href="#2-添加包含目录" class="headerlink" title="2. 添加包含目录"></a><strong>2. 添加包含目录</strong></h4><p>　　依次选择项目—&gt;属性—&gt;VC++目录—&gt;包含目录—&gt;编辑<br>　　找到你的包含目录添加就可以了，最好添加三个，我的是这样的：<br>　　D:\opencv\build\include<br>　　D:\opencv\build\include\opencv<br>　　D:\opencv\build\include\opencv2<br>　　<img src="https://vistary.gitee.io/imgbed/images/opencv_install/20180807111405562.jpg" alt="这里写图片描述">　　</p><h4 id="3-添加库目录"><a href="#3-添加库目录" class="headerlink" title="3.添加库目录"></a><strong>3.添加库目录</strong></h4><p>　　依次选择项目—&gt;属性—&gt;VC++目录—&gt;库目录—&gt;编辑<br>　　我的是D:\opencv\build\x64\vc15\lib<br><img src="https://vistary.gitee.io/imgbed/images/opencv_install/20180807111831210.jpg" alt="这里写图片描述"></p><h4 id="4-添加附加依赖项"><a href="#4-添加附加依赖项" class="headerlink" title="4.添加附加依赖项"></a><strong>4.添加附加依赖项</strong></h4><p>　　依次选择项目—&gt;属性—&gt;链接器—&gt;输入—&gt;附加依赖项—&gt;编辑<br>　　添加你的库文件名<br>　　<img src="https://vistary.gitee.io/imgbed/images/opencv_install/20180807112228800.jpg" alt="这里写图片描述"><br>　　库文件这样找：<br>　　<img src="https://vistary.gitee.io/imgbed/images/opencv_install/20180807112415822.jpg" alt="这里写图片描述"><br>　　有两个文件opencv_world341d.lib和opencv_world341.lib<br>　　如果配置为Debug，选择opencv_world341d.lib<br>　　如果为Release，选择opencv_world341.lib<br>　　这里注意，如果你下载的是OpenCV2.x版本，这里的库文件比较多，都填进去就可以了。</p><p><strong>到这里OpenCV的所有安装部署就结束了，可以进行下一步的使用和学习了。</strong>　　</p>]]></content>
    
    
    <categories>
      
      <category>OpenCV</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机视觉</tag>
      
      <tag>OpenCV</tag>
      
      <tag>图像处理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2020/03/28/hello%20world/"/>
    <url>/2020/03/28/hello%20world/</url>
    
    <content type="html"><![CDATA[<p>终于把美美的博客搭起来了，其实以前就搭过博客，不过都是为了练手，最近看了好多大牛的作品，感觉也要积累打怪升级了。</p><p>在CSDN写过一些博客，但还是感觉自己搭的比较有成就感，正好疫情在家，果断搞起来。</p><p>2020年这个特殊的时期，全国全世界，令人感动的一幕幕不断上演，而我的博客也出生了。以后的你来看到，会不会想起那时事情呢？</p><p>祝我的博客生日快乐，祝我打怪不断升级。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Hello World</tag>
      
      <tag>生日快乐！</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
